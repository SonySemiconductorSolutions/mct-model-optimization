{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09f31596-c293-4faa-8253-336769f8faa5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Quantization Aware Training using the Model Compression Toolkit - example in Keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1a972f-01a5-4b56-8ce7-ecfdb6daf942",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This tutorial will show how to use the Quantization Aware Training API of the Model Compression Toolkit. We will train a model on the MNIST dataset and quantize it with the Model Compression Toolkit QAT API.",
    "[Run this tutorial in Google Colab](https://colab.research.google.com/github/elad-c/model_optimization/blob/main/tutorials/example_keras_qat.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80481dd9-1e3c-4677-9d94-33f144ec540c",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Install relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b380c492-3c53-4ec1-987e-de693a1ec1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The repository located at piprep-ub18 is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherwise you may silence this warning and allow it anyway with '--trusted-host piprep-ub18'.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The repository located at piprep-ub18 is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherwise you may silence this warning and allow it anyway with '--trusted-host piprep-ub18'.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The repository located at piprep-ub18 is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherwise you may silence this warning and allow it anyway with '--trusted-host piprep-ub18'.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The repository located at piprep-ub18 is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherwise you may silence this warning and allow it anyway with '--trusted-host piprep-ub18'.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The repository located at piprep-ub18 is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherwise you may silence this warning and allow it anyway with '--trusted-host piprep-ub18'.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The repository located at piprep-ub18 is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherwise you may silence this warning and allow it anyway with '--trusted-host piprep-ub18'.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The repository located at piprep-ub18 is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherwise you may silence this warning and allow it anyway with '--trusted-host piprep-ub18'.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The repository located at piprep-ub18 is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherwise you may silence this warning and allow it anyway with '--trusted-host piprep-ub18'.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The repository located at piprep-ub18 is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherwise you may silence this warning and allow it anyway with '--trusted-host piprep-ub18'.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The repository located at piprep-ub18 is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherwise you may silence this warning and allow it anyway with '--trusted-host piprep-ub18'.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The repository located at piprep-ub18 is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherwise you may silence this warning and allow it anyway with '--trusted-host piprep-ub18'.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The repository located at piprep-ub18 is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherwise you may silence this warning and allow it anyway with '--trusted-host piprep-ub18'.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The repository located at piprep-ub18 is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherwise you may silence this warning and allow it anyway with '--trusted-host piprep-ub18'.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The repository located at piprep-ub18 is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherwise you may silence this warning and allow it anyway with '--trusted-host piprep-ub18'.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The repository located at piprep-ub18 is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherwise you may silence this warning and allow it anyway with '--trusted-host piprep-ub18'.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The repository located at piprep-ub18 is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherwise you may silence this warning and allow it anyway with '--trusted-host piprep-ub18'.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The repository located at piprep-ub18 is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherwise you may silence this warning and allow it anyway with '--trusted-host piprep-ub18'.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The repository located at piprep-ub18 is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherwise you may silence this warning and allow it anyway with '--trusted-host piprep-ub18'.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The repository located at piprep-ub18 is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherwise you may silence this warning and allow it anyway with '--trusted-host piprep-ub18'.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The repository located at piprep-ub18 is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherwise you may silence this warning and allow it anyway with '--trusted-host piprep-ub18'.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install -q tensorflow\n",
    "! pip install -q model-compression-toolkit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d49c27b1-65f9-4fd3-be3e-733f4c60124a",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "/data/projects/swat/envs/eladc/jupyterlab/lib/python3.8/site-packages/tensorflow/python/platform/../../core/platform/_cpu_feature_guard.so: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mnist\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model, layers, datasets\n",
      "File \u001b[0;32m/data/projects/swat/envs/eladc/jupyterlab/lib/python3.8/site-packages/tensorflow/__init__.py:37\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m/data/projects/swat/envs/eladc/jupyterlab/lib/python3.8/site-packages/tensorflow/python/__init__.py:36\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# go/tf-wildcard-import\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n",
      "File \u001b[0;32m/data/projects/swat/envs/eladc/jupyterlab/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow.py:26\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m self_check\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Cleanup antipattern: import for side effects.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Perform pre-load sanity checks in order to produce a more actionable error.\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[43mself_check\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreload_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     31\u001b[0m   \u001b[38;5;66;03m# This import is expected to fail if there is an explicit shared object\u001b[39;00m\n\u001b[1;32m     32\u001b[0m   \u001b[38;5;66;03m# dependency (with_framework_lib=true), since we do not need RTLD_GLOBAL.\u001b[39;00m\n",
      "File \u001b[0;32m/data/projects/swat/envs/eladc/jupyterlab/lib/python3.8/site-packages/tensorflow/python/platform/self_check.py:65\u001b[0m, in \u001b[0;36mpreload_check\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m   \u001b[38;5;66;03m# Load a library that performs CPU feature guard checking as a part of its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m   \u001b[38;5;66;03m# static initialization. Doing this here as a preload check makes it more\u001b[39;00m\n\u001b[1;32m     61\u001b[0m   \u001b[38;5;66;03m# likely that we detect any CPU feature incompatibilities before we trigger\u001b[39;00m\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;66;03m# them (which would typically result in SIGILL).\u001b[39;00m\n\u001b[1;32m     63\u001b[0m   cpu_feature_guard_library \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m     64\u001b[0m       os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../core/platform/_cpu_feature_guard.so\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m   \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcpu_feature_guard_library\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/projects/swat/envs/eladc/jupyterlab/lib/python3.8/ctypes/__init__.py:373\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 373\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[0;31mOSError\u001b[0m: /data/projects/swat/envs/eladc/jupyterlab/lib/python3.8/site-packages/tensorflow/python/platform/../../core/platform/_cpu_feature_guard.so: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras import Model, layers, datasets\n",
    "import model_compression_toolkit as mct\n",
    "from model_compression_toolkit.qat.keras.quantization_facade import DEFAULT_KERAS_TPC as default_tpc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7c811e-cba8-44f3-888f-e7452a68087d",
   "metadata": {},
   "source": [
    "## Init Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690ff5ae-4474-4876-835f-ab2a2bbcb139",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "_input = layers.Input(shape=input_shape)\n",
    "x = layers.Conv2D(16, 3, strides=2, padding='same', activation='relu')(_input)\n",
    "x = layers.Conv2D(32, 3, strides=2, padding='same', activation='relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=_input, outputs=x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7094f140-f86a-4d76-9042-83a0c99a796e",
   "metadata": {},
   "source": [
    "## Init MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464f2afd-0e80-4a80-86dd-1a26c7d3ea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and split it between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
    "\n",
    "# Normalize images\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "# Add Channels axis to data\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00ab0db-ec7d-4d55-9c52-3440289e4ae1",
   "metadata": {},
   "source": [
    "## Train a Keras classifier model on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a75d82e-e2a0-4204-a4b5-31263bc4b117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train float model\n",
    "batch_size = 128\n",
    "epochs = 15\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
    "\n",
    "# evaluate float model\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Float model test accuracy: {score[1]:02.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd0d525-4bc1-4958-ac67-d114bd25a001",
   "metadata": {},
   "source": [
    "## Prepare model for Hardware-Friendly Quantization Aware Training with MCT\n",
    "The MCT takes the float model and quantizes it in a post-training quantization fashion. Then returns a QAT ready model to the user for Quantization Aware Training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c171d2d-6f0d-474d-aab6-22b0b0c9e71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_representative_dataset():\n",
    "    def _generator():\n",
    "        for _img in x_train:\n",
    "            yield [_img[np.newaxis, ...]]\n",
    "    return _generator().__next__\n",
    "\n",
    "\n",
    "# Set quantization params to: 2 bits for weights, 3 bits for activations\n",
    "default_tpc.tp_model.default_qco.base_config.weights_n_bits = 2\n",
    "default_tpc.tp_model.default_qco.base_config.activation_n_bits = 3\n",
    "\n",
    "qat_model, _, custom_objects = mct.keras_quantization_aware_training_init(model,\n",
    "                                                                          gen_representative_dataset(),\n",
    "                                                                          core_config=mct.CoreConfig(n_iter=10),\n",
    "                                                                          target_platform_capabilities=default_tpc)\n",
    "\n",
    "qat_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "score = qat_model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"PTQ model test accuracy: {score[1]:02.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c74675-b4b5-42bd-a0b7-75da240cbf66",
   "metadata": {},
   "source": [
    "## User Quantization Aware Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3f1d23-9610-415a-84c2-8ef953370574",
   "metadata": {},
   "outputs": [],
   "source": [
    "qat_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
    "\n",
    "score = qat_model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"QAT model test accuracy: {score[1]:02.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94058416-77f3-4930-8090-a50ab5528cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finalize QAT model\n",
    "Remove QuantizeQrapper layers and leave only layers with quantized weights (FakeQuant values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856de5a6-29d6-4e65-80b1-9f11ed63ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = mct.keras_quantization_aware_training_finalize(qat_model)\n",
    "\n",
    "quantized_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "score = quantized_model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Quantized model test accuracy: {score[1]:02.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
