{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Post Training Quantization an EfficientDet Object Detection Model\n",
    "\n",
    "[Run this tutorial in Google Colab](https://colab.research.google.com/github/sony/model_optimization/blob/main/tutorials/notebooks/example_keras_effdet_lite0.ipynb)\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this notebook, we'll demonstrate the post-training quantization using MCT for a pre-trained object detection model in Keras. Specifically, we'll integrate a post-processing custom layer from [sony-custom-layers](https://github.com/sony/custom_layers) into the model. This integration aligns with the imx500 target platform capabilities.\n",
    "\n",
    "In this example we will use an existing pre-trained EfficientDet model taken from [efficientdet-pytorch](https://github.com/rwightman/efficientdet-pytorch). We will convert the model to a Keras functional model that includes the custom [PostProcess Layer](https://github.com/sony/custom_layers/blob/main/sony_custom_layers/keras/object_detection/ssd_post_process.py). Further, we will quantize the model using MCT post training quantization and evaluate the performance of the floating point model and the quantized model on the COCO dataset.\n",
    "\n",
    "We'll use the [timm](https://github.com/huggingface/pytorch-image-models)'s data loader and evaluation capabilities used for the original pytorch pretrained model. The conversion to the Keras model will not be covered. You can go over the conversion [here](https://github.com/sony/model_optimization/tree/main/tutorials/resources/efficientdet)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9e7b10d2bfe67d4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "\n",
    "install and import relevant packages"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0e81b09e6d30873"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install model-compression-toolkit\n",
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install timm\n",
    "!pip install effdet\n",
    "!git clone https://github.com/sony/model_optimization/tree/main/tutorials/resources"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6695a3ec84402e29"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to convert the PyTorch you'll need to use the conversion code in the [MCT tutorials folder](https://github.com/sony/model_optimization/tree/main/tutorials)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eda6ab0d8f0b6b56"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from time import time\n",
    "import torch\n",
    "from timm.utils import AverageMeter\n",
    "from effdet.config import get_efficientdet_config\n",
    "from effdet import create_dataset, create_loader, create_evaluator\n",
    "from effdet.data import resolve_input_config\n",
    "import model_compression_toolkit as mct\n",
    "from resources.efficientdet import EfficientDetKeras, TorchWrapper\n",
    "from resources.utils import load_state_dict"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38e460c939d89482"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Init data loader and evaluation functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6010ecf194d4a6a1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_coco_dataloader(batch_size=16, split='val', config=None):\n",
    "    root = '/data/projects/swat/datasets_src/COCO'\n",
    "\n",
    "    args = dict(interpolation='bilinear', mean=None, std=None, fill_color=None)\n",
    "    dataset = create_dataset('coco', root, split)\n",
    "    input_config = resolve_input_config(args, config)\n",
    "    loader = create_loader(\n",
    "        dataset,\n",
    "        input_size=input_config['input_size'],\n",
    "        batch_size=batch_size,\n",
    "        use_prefetcher=True,\n",
    "        interpolation=input_config['interpolation'],\n",
    "        fill_color=input_config['fill_color'],\n",
    "        mean=input_config['mean'],\n",
    "        std=input_config['std'],\n",
    "        num_workers=0,\n",
    "        pin_mem=False,\n",
    "    )\n",
    "    evaluator = create_evaluator('coco', dataset, pred_yxyx=False)\n",
    "\n",
    "    return loader, evaluator\n",
    "\n",
    "\n",
    "def acc_eval(_model, batch_size=16, config=None):\n",
    "    val_loader, evaluator = get_coco_dataloader(batch_size=batch_size, config=config)\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    end = time()\n",
    "    last_idx = len(val_loader) - 1\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            output = _model(input, img_info=target)\n",
    "\n",
    "            evaluator.add_predictions(output, target)\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time() - end)\n",
    "            end = time()\n",
    "            if i % 10 == 0 or i == last_idx:\n",
    "                print(\n",
    "                    f'Test: [{i:>4d}/{len(val_loader)}]  '\n",
    "                    f'Time: {batch_time.val:.3f}s ({batch_time.avg:.3f}s, {input.size(0) / batch_time.avg:>7.2f}/s)  '\n",
    "                )\n",
    "\n",
    "    return evaluator.evaluate()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5833c805a1ca77aa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create the model and copy weights from pretrained PyTorch weights file"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e589b01c6a45a9e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_name = 'tf_efficientdet_lite0'\n",
    "config = get_efficientdet_config(model_name)\n",
    "\n",
    "merged_outputs = True\n",
    "use_custom_layer = True\n",
    "pretrained_backbone = False\n",
    "model = EfficientDetKeras(config,\n",
    "                          pretrained_backbone=pretrained_backbone\n",
    "                          ).get_model([*config.image_size] + [3],\n",
    "                                      merge_outputs=merged_outputs,\n",
    "                                      use_custom_layer=use_custom_layer)\n",
    "\n",
    "state_dict = torch.hub.load_state_dict_from_url(config.url, progress=False,\n",
    "                                                map_location='cpu')\n",
    "state_dict_numpy = {k: v.numpy() for k, v in state_dict.items()}\n",
    "load_state_dict(model, state_dict_numpy)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f1dacee7a949928"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wrap model in a Torch Module so it can be evaluated with timm's evaluation code"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef6b474a69358e03"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wrapped_model = TorchWrapper(model,\n",
    "                             merged_outputs=merged_outputs,\n",
    "                             used_custom_layer=use_custom_layer)\n",
    "\n",
    "float_map = acc_eval(wrapped_model, batch_size=64, config=config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc2c87ab3460f395"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Quantize Keras model\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aca80a0fc370eef3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loader, _ = get_coco_dataloader(split='train', config=config)\n",
    "\n",
    "\n",
    "def get_representative_dataset(n_iter):\n",
    "\n",
    "    def representative_dataset():\n",
    "        ds_iter = iter(loader)\n",
    "        for _ in range(n_iter):\n",
    "            t = next(ds_iter)[0]\n",
    "            yield [t.detach().cpu().numpy().transpose((0, 2, 3, 1))]\n",
    "\n",
    "    return representative_dataset\n",
    "\n",
    "\n",
    "quant_model, _ = mct.ptq.keras_post_training_quantization_experimental(model,\n",
    "                                                                       get_representative_dataset(20))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f1fa147c5a16df"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wrap quantized model in a Torch Module so it can be evaluated with timm's evaluation code"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79ae299b0b019953"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wrapped_model = TorchWrapper(quant_model,\n",
    "                             merged_outputs=merged_outputs,\n",
    "                             used_custom_layer=use_custom_layer)\n",
    "\n",
    "quant_map = acc_eval(wrapped_model, batch_size=64, config=config)\n",
    "\n",
    "print(f' ===>> Float mAP = {100*float_map:2.3f}, Quantized model mAP = {100*quant_map:2.3f}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f93b9b932fb39cc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
