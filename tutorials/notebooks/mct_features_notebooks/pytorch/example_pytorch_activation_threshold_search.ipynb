{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8194007-6ea7-4e00-8931-a37ca2d0dd20",
   "metadata": {
    "id": "f8194007-6ea7-4e00-8931-a37ca2d0dd20"
   },
   "source": [
    "# A Practical Guide to Activation Threshold Search in Post-Training Quantization\n",
    "\n",
    "[Run this tutorial in Google Colab](https://colab.research.google.com/github/sony/model_optimization/blob/main/tutorials/notebooks/mct_features_notebooks/keras/example_keras_activation_threshold_search.ipynb)\n",
    "\n",
    "## Overview\n",
    "This tutorial demonstrates how to find the optimal activation threshold, a key component in MCT's post-training quantization workflow.\n",
    "\n",
    "In this example, we will explore two different metrics for threshold selection. We will begin by applying the appropriate MCT configurations, followed by inferring a representative dataset through the model. Next, we will plot the activation distributions of two layers along with their corresponding MCT-calculated thresholds, and finally, we will compare the quantized model accuracy using both methods.\n",
    "\n",
    "## Activation threshold explanation\n",
    "During the quantization process, thresholds are used to map a distribution of 32-bit floating-point values to their quantized equivalents. Minimizing data loss while preserving the most representative range is crucial for maintaining the final model's accuracy.\n",
    "\n",
    "### How Is It Done in MCT?\n",
    "\n",
    "MCT's post-training quantization leverages a representative dataset to evaluate a range of typical output activation values. The challenge lies in determining the best way to map these values to their quantized versions. To address this, a grid search is performed to find the optimal threshold using various error metrics. Typically, mean squared error (MSE) is the most effective and is used as the default metric.\n",
    "\n",
    "The error is calculated based on the difference between the original float and the quantized distributions. The optimal threshold is then selected based on the metric that results in the minimum error. For example, for the case of MSE.\n",
    "\n",
    "$$\n",
    "ERR(t) = \\frac{1}{n_s} \\sum_{X \\in Fl(D)} (Q(X, t, n_b) - X)^2\n",
    "$$\n",
    "\n",
    "- $ERR(t)$ : The quantization error function dependent on the threshold $t$.\n",
    "- \n",
    "- $n_s$: The size of the representative dataset.\n",
    "\n",
    "- $\\sum$: Summation over all elements $X$ in the flattened dataset $F_l(D)$.\n",
    "\n",
    "- $F_l(D)$: The set of activation tensors in the $l$-th layer, flattened for processing.\n",
    "\n",
    "- $Q(X, t, n_b)$: The quantized approximation of $X$, given a threshold $t$ and bit width $n_b$.\n",
    "\n",
    "- $X$: The original activation tensor before quantization.\n",
    "\n",
    "- $t$: The quantization threshold, a key parameter for controlling the quantization process.\n",
    "\n",
    "- $n_b$: The number of bits used in quantization, impacting model precision and size.\n",
    "\n",
    "\n",
    "Quantization thresholds often have specific limitations, typically imposed for deployment purposes. In MCT, activation thresholds are restricted by default to Power-of-Two values and can represent either signed values within the range $(-T, T)$ or unsigned values within $(0, T)$. Other restriction settings are also configurable.\n",
    "\n",
    "### Error methods supported by MCT:\n",
    "\n",
    "- **NOCLIPPING:** Use min/max values as thresholds.\n",
    "\n",
    "- **MSE:** Minimizes quantization noise by using the mean squared error (MSE).\n",
    "\n",
    "- **MAE:** Minimizes quantization noise by using the mean absolute error (MAE).\n",
    "\n",
    "- **KL:** Uses Kullback-Leibler (KL) divergence to align the distributions, ensuring that the quantized distribution is as similar as possible to the original.\n",
    "\n",
    "- **Lp:** Minimizes quantization noise using the Lp norm, where `p` is a configurable parameter that determines the type of distance metric.\n",
    "\n",
    "## Setup\n",
    "Install the relevant packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb67cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "324685b9-5dcc-4d22-80f4-dec9a93d3324",
   "metadata": {
    "id": "324685b9-5dcc-4d22-80f4-dec9a93d3324",
    "tags": []
   },
   "outputs": [],
   "source": [
    "TORCH_VER = \"2.4.0\"\n",
    "if not importlib.util.find_spec('torch'):\n",
    "    !pip install -q torch=={TORCH_VER} torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7837babf2112542b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "if not importlib.util.find_spec('model_compression_toolkit'):\n",
    "    !pip install model_compression_toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3f0acc8-281c-4bca-b0b9-3d7677105f19",
   "metadata": {
    "id": "b3f0acc8-281c-4bca-b0b9-3d7677105f19"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import mobilenet_v2, MobileNet_V2_Weights\n",
    "from torchvision.datasets import ImageNet\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d691159f5bfc53e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Load a pre-trained MobileNetV2 model from Keras, in 32-bits floating-point precision format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "468d67cd5f25886e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = MobileNet_V2_Weights.IMAGENET1K_V2\n",
    "\n",
    "float_model = mobilenet_v2(weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5a1be0c4fc4847",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Dataset preparation\n",
    "### Download the ImageNet validation set\n",
    "Download the ImageNet dataset with only the validation split.\n",
    "**Note:** For demonstration purposes we use the validation set for the model quantization routines. Usually, a subset of the training dataset is used, but loading it is a heavy procedure that is unnecessary for the sake of this demonstration.\n",
    "\n",
    "This step may take several minutes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "_ztv72uM6-UT",
   "metadata": {
    "id": "_ztv72uM6-UT"
   },
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "if not os.path.isdir('imagenet'):\n",
    "    !mkdir imagenet\n",
    "    !wget -P imagenet https://image-net.org/data/ILSVRC/2012/ILSVRC2012_devkit_t12.tar.gz\n",
    "    !wget -P imagenet https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d878e0",
   "metadata": {},
   "source": [
    "Extract ImageNet validation dataset using torchvision \"datasets\" module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e5658c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.imagenet.ImageNet'>\n",
      "50000\n",
      "Dataset ImageNet\n",
      "    Number of datapoints: 50000\n",
      "    Root location: ./imagenet\n",
      "    Split: val\n",
      "    StandardTransform\n",
      "Transform: ImageClassification(\n",
      "               crop_size=[224]\n",
      "               resize_size=[232]\n",
      "               mean=[0.485, 0.456, 0.406]\n",
      "               std=[0.229, 0.224, 0.225]\n",
      "               interpolation=InterpolationMode.BILINEAR\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "dataset = ImageNet(root='./imagenet', split='val', transform=weights.transforms())\n",
    "print(type(dataset))\n",
    "print(len(dataset))\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa0bca3e15fba91",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Representative Dataset\n",
    "For quantization with MCT, we need to define a representative dataset required by the PTQ algorithm. This dataset is a generator that returns a list of images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bdb4144e4ce2ab6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "n_iter = 10\n",
    "\n",
    "#dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "def representative_dataset_gen():\n",
    "    dataloader_iter = iter(dataloader)\n",
    "    for _ in range(n_iter):\n",
    "        yield [next(dataloader_iter)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f4bbca00996989",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Target Platform Capabilities\n",
    "MCT optimizes the model for dedicated hardware. This is done using TPC (for more details, please visit our [documentation](https://sony.github.io/model_optimization/api/api_docs/modules/target_platform.html)). Here, we use the default Tensorflow TPC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "554719effaf90250",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import model_compression_toolkit as mct\n",
    "\n",
    "# Get a TargetPlatformCapabilities object that models the hardware platform for the quantized model inference. Here, for example, we use the default platform that is attached to a Pytorch layers representation.\n",
    "target_platform_cap = mct.get_target_platform_capabilities('pytorch', 'default')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1e9ba6-2954-4506-ad5c-0da273701ba5",
   "metadata": {
    "id": "4a1e9ba6-2954-4506-ad5c-0da273701ba5"
   },
   "source": [
    "## Post-Training Quantization using MCT\n",
    "In this step, we load the model and apply post-training quantization using two threshold error calculation methods: **\"No Clipping\"** and **MSE**.\n",
    "\n",
    "- **\"No Clipping\"** selects the lowest power-of-two threshold that ensures no data is lost (clipped).\n",
    "- **MSE** selects a power-of-two threshold that minimizes the mean square error between the original float distribution and the quantized distribution.\n",
    "\n",
    "- As a result, the \"No Clipping\" method typically results in a larger threshold, as we will demonstrate later in this tutorial.\n",
    "\n",
    "The quantization parameters are predefined, and we use the default values except for the quantization method. Feel free to modify the code below to experiment with other error metrics supported by MCT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "jtiZzXmTjxuI",
   "metadata": {
    "id": "jtiZzXmTjxuI"
   },
   "outputs": [],
   "source": [
    "from model_compression_toolkit.core import QuantizationErrorMethod\n",
    "\n",
    "q_configs_dict = {}\n",
    "# Error methods to iterate over\n",
    "error_methods = [\n",
    "    QuantizationErrorMethod.MSE,\n",
    "    QuantizationErrorMethod.NOCLIPPING\n",
    "]\n",
    "\n",
    "# If you are curious you can add any of the below quantization methods as well.\n",
    "# QuantizationErrorMethod.MAE\n",
    "# QuantizationErrorMethod.KL\n",
    "# QuantizationErrorMethod.LP\n",
    "\n",
    "# Iterate and build the QuantizationConfig objects\n",
    "for error_method in error_methods:\n",
    "    q_config = mct.core.QuantizationConfig(\n",
    "        activation_error_method=error_method,\n",
    "    )\n",
    "\n",
    "    q_configs_dict[error_method] = q_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8W3Dcn0jkJOH",
   "metadata": {
    "id": "8W3Dcn0jkJOH"
   },
   "source": [
    "Now we will run post-training quantization for each configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b609660e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND_TORCH True\n"
     ]
    }
   ],
   "source": [
    "FOUND_TORCH = importlib.util.find_spec(\"torch\") is not None\n",
    "print(\"FOUND_TORCH\", FOUND_TORCH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba0c6e55-d474-4dc3-9a43-44b736635998",
   "metadata": {
    "id": "ba0c6e55-d474-4dc3-9a43-44b736635998"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:Model Compression Toolkit:DepthwiseConv2D is not in model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DepthwiseConv2D is not in model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Statistics Collection: 10it [00:10,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running quantization parameters search. This process might take some time, depending on the model size and the selected quantization methods.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating quantization parameters: 100%|██████████| 102/102 [00:17<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please run your accuracy evaluation on the exported quantized model to verify it's accuracy.\n",
      "Checkout the FAQ and Troubleshooting pages for resolving common issues and improving the quantized model accuracy:\n",
      "FAQ: https://github.com/sony/model_optimization/tree/main/FAQ.md\n",
      "Quantization Troubleshooting: https://github.com/sony/model_optimization/tree/main/quantization_troubleshooting.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:Model Compression Toolkit:DepthwiseConv2D is not in model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DepthwiseConv2D is not in model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Statistics Collection: 10it [00:09,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running quantization parameters search. This process might take some time, depending on the model size and the selected quantization methods.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating quantization parameters: 100%|██████████| 102/102 [00:16<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please run your accuracy evaluation on the exported quantized model to verify it's accuracy.\n",
      "Checkout the FAQ and Troubleshooting pages for resolving common issues and improving the quantized model accuracy:\n",
      "FAQ: https://github.com/sony/model_optimization/tree/main/FAQ.md\n",
      "Quantization Troubleshooting: https://github.com/sony/model_optimization/tree/main/quantization_troubleshooting.md\n"
     ]
    }
   ],
   "source": [
    "quantized_models_dict = {}\n",
    "\n",
    "for error_method, q_config in q_configs_dict.items():\n",
    "    # Create a CoreConfig object with the current quantization configuration\n",
    "    ptq_config = mct.core.CoreConfig(quantization_config=q_config)\n",
    "\n",
    "    # Perform MCT post-training quantization\n",
    "    quantized_model, quantization_info = mct.ptq.pytorch_post_training_quantization(\n",
    "        in_module=float_model,\n",
    "        representative_data_gen=representative_dataset_gen,\n",
    "        core_config=ptq_config,\n",
    "        target_platform_capabilities=target_platform_cap\n",
    "    )\n",
    "\n",
    "    # Update the dictionary to include the quantized model\n",
    "    quantized_models_dict[error_method] = {\n",
    "        \"quantization_config\": q_config,\n",
    "        \"quantized_model\": quantized_model,\n",
    "        \"quantization_info\": quantization_info\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24ae88fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'model_compression_toolkit.core.pytorch.back2framework.pytorch_model_builder.PytorchModel'>\n",
      "PytorchActivationQuantizationHolder()\n",
      "<class 'model_compression_toolkit.core.pytorch.back2framework.pytorch_model_builder.PytorchModel'>\n",
      "<class 'mct_quantizers.pytorch.activation_quantization_holder.PytorchActivationQuantizationHolder'>\n",
      "<mct_quantizers.pytorch.quantizers.activation_inferable_quantizers.activation_pot_inferable_quantizer.ActivationPOTInferableQuantizer object at 0x7fed9d2cae30>\n",
      "8.0\n"
     ]
    }
   ],
   "source": [
    "import mct_quantizers\n",
    "\n",
    "import mct_quantizers.pytorch.quantizers.activation_inferable_quantizers.activation_pot_inferable_quantizer\n",
    "\n",
    "#print(quantized_models_dict)\n",
    "print(type(quantized_models_dict[QuantizationErrorMethod.MSE]['quantized_model']))\n",
    "#print(quantized_models_dict[QuantizationErrorMethod.MSE]['quantized_model'].features_0_2.activation_holder_quantizer)\n",
    "\n",
    "wkm = quantized_models_dict[QuantizationErrorMethod.MSE]['quantized_model']\n",
    "wkc = quantized_models_dict[QuantizationErrorMethod.MSE]['quantization_config']\n",
    "wki = quantized_models_dict[QuantizationErrorMethod.MSE]['quantization_info']\n",
    "\n",
    "print(wkm.features_1_conv_0_2_activation_holder_quantizer)\n",
    "print(type(wkm))\n",
    "print(type(wkm.features_1_conv_0_2_activation_holder_quantizer))\n",
    "print(wkm.features_1_conv_0_2_activation_holder_quantizer.activation_holder_quantizer)\n",
    "print(wkm.features_1_conv_0_2_activation_holder_quantizer.activation_holder_quantizer.threshold_np)\n",
    "#print(wkm.features_1_conv_0_2_activation_holder_quantizer.activation_holder_quantizer.get_config())\n",
    "#print(wkc)\n",
    "#print(wki)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for error_method, data in quantized_models_dict.items():\n",
    "    ##print(error_method)\n",
    "    #print(data['quantized_model'].features_0_0_bn.layer)\n",
    "    #print(type(data['quantized_model'].features_0_0_bn))\n",
    "    #print(error_method, data)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "A8UHRsh2khM4",
   "metadata": {
    "id": "A8UHRsh2khM4"
   },
   "source": [
    "## Threshold and Distribution Visualization\n",
    "To facilitate understanding, we will plot the activation distributions for two layers of MobileNetV2. For each layer, we will show the thresholds determined by both **MSE** and **No Clipping** methods, along with the corresponding activation distributions obtained by infering the representative dataset through the model. This visualization highlights the trade-off between data loss and data resolution under different thresholds during quantization.\n",
    "\n",
    "MCT’s `quantization_info` stores the threshold values for each layer. However, to view the actual activation distributions, the model needs to be reconstructed up to and including the target layer selected for visualization.\n",
    "\n",
    "To do this, we first need to identify the layer names. In Keras, this can be easily done for the first 10 layers using the following code snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a22e6d68-c40f-40bf-ab74-ff453011aeac",
   "metadata": {
    "id": "a22e6d68-c40f-40bf-ab74-ff453011aeac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 0\n",
      " MobileNetV2(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): Conv2dNormActivation(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "### 1\n",
      "features Sequential(\n",
      "  (0): Conv2dNormActivation(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU6(inplace=True)\n",
      "  )\n",
      "  (1): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (2): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (3): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (4): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (5): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (6): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (7): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (8): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (9): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (10): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (11): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (12): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (13): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (14): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (15): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (16): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (17): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (18): Conv2dNormActivation(\n",
      "    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU6(inplace=True)\n",
      "  )\n",
      ")\n",
      "### 2\n",
      "features.0 Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "### 3\n",
      "features.0.0 Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "### 4\n",
      "features.0.1 BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "### 5\n",
      "features.0.2 ReLU6(inplace=True)\n",
      "### 6\n",
      "features.1 InvertedResidual(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "### 7\n",
      "features.1.conv Sequential(\n",
      "  (0): Conv2dNormActivation(\n",
      "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU6(inplace=True)\n",
      "  )\n",
      "  (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "### 8\n",
      "features.1.conv.0 Conv2dNormActivation(\n",
      "  (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "### 9\n",
      "features.1.conv.0.0 Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n"
     ]
    }
   ],
   "source": [
    "for index, (name, layer) in enumerate(float_model.named_modules()):\n",
    "    if index < 10:\n",
    "        print(\"###\", index)\n",
    "        print(name, layer)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38d28f3-c947-4c7c-aafa-e96cc3864277",
   "metadata": {
    "id": "c38d28f3-c947-4c7c-aafa-e96cc3864277"
   },
   "source": [
    "The first activation layer in the model is named `ReLU6`.\n",
    "\n",
    "For this particular model, testing has shown that the `BatchNorm2d` layer exhibits different thresholds for the two error metrics. Therefore, we will also include this layer in the visualization. For context, MobileNetV2 uses an inverted residual structure, where the input is first expanded in the channel dimension, then passed through a depthwise convolution, and finally projected back to a lower dimension. The `BatchNorm2d` layer represents this projection, and the BN suffix indicates the presence of Batch Normalization.\n",
    "\n",
    "We will use these layer names to create two separate models, each ending at one of these respective layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f9dd3f3-6e22-4be9-9beb-29568ff14c9d",
   "metadata": {
    "id": "1f9dd3f3-6e22-4be9-9beb-29568ff14c9d"
   },
   "outputs": [],
   "source": [
    "layer_name1 = 'features.0.2'             # Conv1_reluに相当\n",
    "layer_name2 = 'features.1.conv.1'       # expanded_conv_project_BNに相当\n",
    "\n",
    "# 特定のレイヤーの出力を取得するためのフックを設定\n",
    "def get_layer_output(model, layer_name):\n",
    "    outputs = {}\n",
    "\n",
    "    def hook(module, input, output):\n",
    "        outputs[layer_name] = output\n",
    "\n",
    "    # 指定したレイヤーにフックを追加\n",
    "    layer = dict(model.named_modules())[layer_name]  # モジュール名を辞書形式で取得\n",
    "    layer.register_forward_hook(hook)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "\n",
    "# Conv1_reluの出力を取得\n",
    "output_dict_relu = get_layer_output(float_model, layer_name1)\n",
    "\n",
    "# expanded_conv_project_BNの出力を取得（features.1.conv.1 は活性化関数の次）\n",
    "output_dict_project = get_layer_output(float_model, layer_name2)\n",
    "\n",
    "# モデルに入力データを通す\n",
    "#input_tensor = torch.randn(1, 3, 224, 224)  # バッチサイズ1の入力データ\n",
    "#float_model(input_tensor)\n",
    "\n",
    "# それぞれの出力を取得\n",
    "#output_relu = output_dict_relu[layer_name1]\n",
    "#output_project = output_dict_project[layer_name2]\n",
    "\n",
    "#print(f\"Output from {layer_name1}:\", output_relu.shape)\n",
    "#print(f\"Output from {layer_name2}:\", output_project.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc81508-01e5-421c-9b48-6ed3ce5b7364",
   "metadata": {
    "id": "ccc81508-01e5-421c-9b48-6ed3ce5b7364"
   },
   "source": [
    "Infer the representative dataset using these models and store the outputs for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaeb9888-5d67-4979-af50-80781a811b4b",
   "metadata": {
    "id": "eaeb9888-5d67-4979-af50-80781a811b4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0+cu121\n",
      "cuda:0\n",
      "NVIDIA GeForce RTX 3090\n",
      "(8, 6)\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name())\n",
    "print(torch.cuda.get_device_capability())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a5bf3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/6250 [00:00<06:27, 16.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         ... 0.24012035 1.2019204  1.4022245 ] 35323904\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.25255647\n",
      "0.6007481\n",
      "0.6139736\n",
      "0.25284094\n",
      "0.0\n",
      "0.0\n",
      "0.25791883\n",
      "0.15303095\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "activation_batches_relu = []\n",
    "activation_batches_project = []\n",
    "with torch.no_grad():\n",
    "    float_model = float_model.to(device)\n",
    "    for index, data in enumerate(tqdm(dataloader)):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        float_model(images)\n",
    "\n",
    "        activations_relu = output_dict_relu[layer_name1]\n",
    "        #activation_batches_relu.append(activations_relu.to('cpu'))\n",
    "        activation_batches_relu.append(activations_relu.to('cpu').detach().numpy().copy())\n",
    "        activations_project = output_dict_project[layer_name2]\n",
    "        #activation_batches_project.append(activations_project.to('cpu'))\n",
    "        activation_batches_project.append(activations_project.to('cpu').detach().numpy().copy())\n",
    "\n",
    "        #print(\"images.shape\", images.shape, type(images))\n",
    "        #print(\"images0\", images[0])\n",
    "        #print(\"activations_relu\", type(activations_relu))\n",
    "        #print(\"activations_relu.shape\", activations_relu.shape)\n",
    "        #print(\"activations_project\", type(activations_project))\n",
    "        #print(\"activations_project.shape\", activations_project.shape)\n",
    "\n",
    "        del(activations_relu)\n",
    "        del(activations_project)\n",
    "        del(data)\n",
    "        del(images)\n",
    "        del(labels)\n",
    "        \n",
    "        if index >= 10:\n",
    "            break\n",
    "\n",
    "    all_activations_relu = np.concatenate(activation_batches_relu, axis=0).flatten()\n",
    "    all_activations_project = np.concatenate(activation_batches_project, axis=0).flatten()\n",
    "\n",
    "print(all_activations_relu, len(all_activations_relu))\n",
    "for i in range(20):\n",
    "    print(all_activations_relu[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I5W9yY5DvOFr",
   "metadata": {
    "id": "I5W9yY5DvOFr"
   },
   "source": [
    "Thresholds calculated by MCT during quantization can be accessed using the following approach. The layer indices correspond to the order of the layers listed in the previous steps.\n",
    "\n",
    "As noted earlier, we focus on the first ReLU activation layer and the Batch Normalization layer (`expanded_conv_project_BN`) since they effectively illustrate the impact of the two threshold error methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20b6ad11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PytorchModel(\n",
      "  (x): DummyPlaceHolder()\n",
      "  (x_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_0_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      "  (features_0_2): ReLU6(inplace=True)\n",
      "  (features_0_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_1_conv_0_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
      "  )\n",
      "  (features_1_conv_0_2): ReLU6(inplace=True)\n",
      "  (features_1_conv_0_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_1_conv_1_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_1_conv_1_bn_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_2_conv_0_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_2_conv_0_2): ReLU6(inplace=True)\n",
      "  (features_2_conv_0_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_2_conv_1_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96)\n",
      "  )\n",
      "  (features_2_conv_1_2): ReLU6(inplace=True)\n",
      "  (features_2_conv_1_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_2_conv_2_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_2_conv_2_bn_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_3_conv_0_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_3_conv_0_2): ReLU6(inplace=True)\n",
      "  (features_3_conv_0_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_3_conv_1_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144)\n",
      "  )\n",
      "  (features_3_conv_1_2): ReLU6(inplace=True)\n",
      "  (features_3_conv_1_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_3_conv_2_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_3_conv_2_bn_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (add_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_4_conv_0_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_4_conv_0_2): ReLU6(inplace=True)\n",
      "  (features_4_conv_0_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_4_conv_1_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144)\n",
      "  )\n",
      "  (features_4_conv_1_2): ReLU6(inplace=True)\n",
      "  (features_4_conv_1_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_4_conv_2_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_4_conv_2_bn_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_5_conv_0_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_5_conv_0_2): ReLU6(inplace=True)\n",
      "  (features_5_conv_0_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_5_conv_1_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "  )\n",
      "  (features_5_conv_1_2): ReLU6(inplace=True)\n",
      "  (features_5_conv_1_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_5_conv_2_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_5_conv_2_bn_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (add_1_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_6_conv_0_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_6_conv_0_2): ReLU6(inplace=True)\n",
      "  (features_6_conv_0_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_6_conv_1_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "  )\n",
      "  (features_6_conv_1_2): ReLU6(inplace=True)\n",
      "  (features_6_conv_1_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_6_conv_2_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_6_conv_2_bn_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (add_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_7_conv_0_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_7_conv_0_2): ReLU6(inplace=True)\n",
      "  (features_7_conv_0_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_7_conv_1_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192)\n",
      "  )\n",
      "  (features_7_conv_1_2): ReLU6(inplace=True)\n",
      "  (features_7_conv_1_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_7_conv_2_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_7_conv_2_bn_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_8_conv_0_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_8_conv_0_2): ReLU6(inplace=True)\n",
      "  (features_8_conv_0_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_8_conv_1_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "  )\n",
      "  (features_8_conv_1_2): ReLU6(inplace=True)\n",
      "  (features_8_conv_1_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_8_conv_2_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_8_conv_2_bn_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (add_3_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_9_conv_0_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_9_conv_0_2): ReLU6(inplace=True)\n",
      "  (features_9_conv_0_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_9_conv_1_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "  )\n",
      "  (features_9_conv_1_2): ReLU6(inplace=True)\n",
      "  (features_9_conv_1_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_9_conv_2_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_9_conv_2_bn_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (add_4_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_10_conv_0_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_10_conv_0_2): ReLU6(inplace=True)\n",
      "  (features_10_conv_0_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_10_conv_1_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "  )\n",
      "  (features_10_conv_1_2): ReLU6(inplace=True)\n",
      "  (features_10_conv_1_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_10_conv_2_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_10_conv_2_bn_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (add_5_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_11_conv_0_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_11_conv_0_2): ReLU6(inplace=True)\n",
      "  (features_11_conv_0_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_11_conv_1_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "  )\n",
      "  (features_11_conv_1_2): ReLU6(inplace=True)\n",
      "  (features_11_conv_1_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_11_conv_2_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_11_conv_2_bn_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_12_conv_0_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_12_conv_0_2): ReLU6(inplace=True)\n",
      "  (features_12_conv_0_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_12_conv_1_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576)\n",
      "  )\n",
      "  (features_12_conv_1_2): ReLU6(inplace=True)\n",
      "  (features_12_conv_1_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_12_conv_2_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_12_conv_2_bn_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (add_6_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_13_conv_0_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_13_conv_0_2): ReLU6(inplace=True)\n",
      "  (features_13_conv_0_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_13_conv_1_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576)\n",
      "  )\n",
      "  (features_13_conv_1_2): ReLU6(inplace=True)\n",
      "  (features_13_conv_1_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_13_conv_2_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_13_conv_2_bn_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (add_7_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_14_conv_0_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_14_conv_0_2): ReLU6(inplace=True)\n",
      "  (features_14_conv_0_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_14_conv_1_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576)\n",
      "  )\n",
      "  (features_14_conv_1_2): ReLU6(inplace=True)\n",
      "  (features_14_conv_1_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_14_conv_2_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_14_conv_2_bn_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_15_conv_0_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_15_conv_0_2): ReLU6(inplace=True)\n",
      "  (features_15_conv_0_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_15_conv_1_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960)\n",
      "  )\n",
      "  (features_15_conv_1_2): ReLU6(inplace=True)\n",
      "  (features_15_conv_1_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_15_conv_2_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_15_conv_2_bn_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (add_8_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_16_conv_0_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_16_conv_0_2): ReLU6(inplace=True)\n",
      "  (features_16_conv_0_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_16_conv_1_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960)\n",
      "  )\n",
      "  (features_16_conv_1_2): ReLU6(inplace=True)\n",
      "  (features_16_conv_1_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_16_conv_2_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_16_conv_2_bn_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (add_9_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_17_conv_0_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_17_conv_0_2): ReLU6(inplace=True)\n",
      "  (features_17_conv_0_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_17_conv_1_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960)\n",
      "  )\n",
      "  (features_17_conv_1_2): ReLU6(inplace=True)\n",
      "  (features_17_conv_1_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_17_conv_2_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_17_conv_2_bn_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (features_18_0_bn): PytorchQuantizationWrapper(\n",
      "    (layer): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (features_18_2): ReLU6(inplace=True)\n",
      "  (features_18_2_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (adaptive_avg_pool2d_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      "  (classifier_0): Dropout(p=0.2, inplace=False)\n",
      "  (classifier_1): PytorchQuantizationWrapper(\n",
      "    (layer): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "  )\n",
      "  (classifier_1_activation_holder_quantizer): PytorchActivationQuantizationHolder()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(quantized_models_dict[QuantizationErrorMethod.MSE]['quantized_model'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "NGnjrPD_uTd5",
   "metadata": {
    "id": "NGnjrPD_uTd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<QuantizationErrorMethod.MSE: 1>: np.float64(8.0), <QuantizationErrorMethod.NOCLIPPING: 0>: np.float64(8.0)}\n",
      "{<QuantizationErrorMethod.MSE: 1>: np.float64(32.0), <QuantizationErrorMethod.NOCLIPPING: 0>: np.float64(64.0)}\n"
     ]
    }
   ],
   "source": [
    "# layer 4 is the first activation layer - Conv1_relu\n",
    "optimal_thresholds_relu = {\n",
    "    error_method: data[\"quantized_model\"].features_0_2_activation_holder_quantizer.activation_holder_quantizer.threshold_np\n",
    "    for error_method, data in quantized_models_dict.items()\n",
    "}\n",
    "\n",
    "print(optimal_thresholds_relu)\n",
    "\n",
    "# layer 9 is the batch normalisation projection layer - Expanded_conv_project_BN\n",
    "optimal_thresholds_project = {\n",
    "    error_method: data[\"quantized_model\"].features_2_conv_2_bn_activation_holder_quantizer.activation_holder_quantizer.threshold_np\n",
    "    for error_method, data in quantized_models_dict.items()\n",
    "}\n",
    "\n",
    "print(optimal_thresholds_project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XRAr8L5mvuLd",
   "metadata": {
    "id": "XRAr8L5mvuLd"
   },
   "source": [
    "### Distribution Plots\n",
    "Below are the activation distributions for the two selected layers: first, the ReLU activation layer, `Conv1_relu`, followed by the `expanded_conv_project_BN` layer.\n",
    "\n",
    "The second distribution clearly highlights the differences between the two error metrics, showing the impact of each on the resulting quantization threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "VPb8tBNGpJjo",
   "metadata": {
    "id": "VPb8tBNGpJjo"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0EAAAIjCAYAAADFthA8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAACET0lEQVR4nOzdd3hT5f//8Vfa0kEpZbUMKbTsPWTJElCGLAEVmcqoCgqy5QMiS0ZBZAkyVKCgIEMBFUX2BtlD9h5KWQItZbS0Ob8/+DVfQlpoQ0to83xcVy7Ife5z7ndO0iTvc4+YDMMwBAAAAABOwsXRAQAAAADAs0QSBAAAAMCpkAQBAAAAcCokQQAAAACcCkkQAAAAAKdCEgQAAADAqZAEAQAAAHAqJEEAAAAAnApJEAAAAACnQhKEp9a+fXsFBgY6pO0hQ4bIZDI5pO2kOnv2rEwmk0JDQ1O8rdDQUJlMJp09e9ZSFhgYqEaNGqV425K0fv16mUwmrV+//pm097SS8tzE1f3yyy9TPrBk5MjnJLW9HpJDzZo1VbNmTadpN7Get7+flIgnvvffhAQGBqp9+/bJ1vbjmEwmDRky5Jm09aw8y/OHtIckyAlMmTJFJpNJlSpVsvsYFy9e1JAhQ7Rv377kCyyR7ty5oyFDhjx3X6BMJpPl5ubmpixZsqhcuXLq3r27Dh8+nGztTJky5ZkkTvZ4nmN7Wn/88UeKfmE4f/68OnfurMDAQHl4eMjf319NmzbVli1bnuq4aeE5OXTokNq2basXXnhBHh4eypUrl9q2bZusf1fJ4fDhwxoyZEiivuymhXYTEhgYaPV+mNAttb8un2dxFxriu7Vs2TJF2kzqe82jcWXMmFE1atTQ77//niLx2SPuwuq1a9ccHQqeATdHB4CUN3fuXAUGBmrHjh06efKkChQokORjXLx4UUOHDlVgYKDKlCljte3bb7+V2WxOpmht3blzR0OHDpUkmyucn332mfr165dibT9JnTp19O6778owDIWHh2v//v2aPXu2pkyZotGjR6tXr16Wunnz5tXdu3eVLl26JLUxZcoUZcuWLUlXu9555x21bNlSHh4eSWorqRKK7eWXX9bdu3fl7u6eou0nl/iemz/++ENff/11iiRCW7ZsUYMGDSRJ7733nooVK6ZLly4pNDRU1atX18SJE/Xxxx/bdezU/pwsXrxYrVq1UpYsWRQcHKygoCCdPXtWM2bM0E8//aQFCxaoSZMmjg5T0oNkZOjQoapZs6ZNb/jKlSvTXLsJmTBhgiIjIy33//jjD/34448aP368smXLZimvUqXKM4/N2XTr1k0VKlSwKot7jdy9e1dubsn3tc+ez6aHPzPPnTunqVOnqnHjxlq+fLnq1auXbLEBiUESlMadOXNGW7du1eLFi9WpUyfNnTtXgwcPTtY2kvqlPjm5ubkl65t6UhUqVEht27a1Khs1apQaN26s3r17q0iRIpYvuyaTSZ6enikaz+3bt+Xt7S1XV1e5urqmaFuP4+LikuKPNTk9i+cmzo0bN/TWW2/Jy8tLW7ZsUf78+S3bevXqpXr16qlHjx4qV65csn5pTA3PyalTp/TOO+8oX7582rhxo/z8/CzbunfvrurVq6tt27Y6cOCAgoKCHBjpkzkq2XREu02bNrW6f+nSJf34449q2rSpTZL2tL1Xce9xiF/16tX11ltvxbstMX//KX1+H/3MfPPNN1WsWDFNnDiRJMgOMTExMpvNz/3FrecVw+HSuLlz5ypz5sxq2LCh3nrrLc2dOzfeejdv3lTPnj0tQ3Ny586td999V9euXdP69estV5Y6dOhgM7Th4TlB9+/fV5YsWdShQwebNiIiIuTp6ak+ffpIkqKjozVo0CCVK1dOvr6+8vb2VvXq1bVu3TrLPmfPnrV8ERo6dKil7bir8/HNCYqJidGwYcOUP39+eXh4KDAwUJ9++qmioqKs6sXNkdm8ebMqVqwoT09P5cuXT3PmzEnaSX5E1qxZNX/+fLm5uWnEiBFWj+XRISGXLl1Shw4dlDt3bnl4eChnzpxq0qSJ5YtCYGCgDh06pA0bNlgee1xvWNy48w0bNuijjz6Sv7+/cufObbUtvi8cK1euVJkyZeTp6alixYpp8eLFVtsTmmf16DEfF1tCc0AWLVqkcuXKycvLS9myZVPbtm3177//WtVp3769MmTIoH///VdNmzZVhgwZ5Ofnpz59+ig2Nvax575Xr17KmjWrDMOwlH388ccymUz66quvLGWXL1+WyWTS1KlTJdk+N+3bt9fXX38tyXoIx6O++eYby+usQoUK2rlz52Pjk6Tp06fr0qVLGjNmjFUCJEleXl6aPXu2TCaTPv/8c0t53LnfuHGjOnXqpKxZsypjxox69913dePGDUu9pD4nNWvWVIkSJXTgwAHVqFFD6dOnV4ECBfTTTz9JkjZs2KBKlSrJy8tLhQsX1urVq63iPXfunD766CMVLlxYXl5eypo1q5o3b273F90xY8bozp07+uabb6wSIEnKli2bpk+frsjISI0ZM8ZSntCcxPhex7NmzdIrr7wif39/eXh4qFixYpbXwMMS894QGhqq5s2bS5Jq1aplOd9x5/fRuTmPGzIWt09izmdS25WkK1euKDg4WNmzZ5enp6dKly6t2bNnW9V5eG6MPa9rezypnbj3glOnTqlBgwby8fFRmzZtJElms1kTJkxQ8eLF5enpqezZs6tTp05Wfw+StGvXLtWrV0/ZsmWTl5eXgoKC1LFjR7vikaS1a9eqevXq8vb2VqZMmdSkSRMdOXLkiY/VMAwNHz5cuXPnVvr06VWrVi0dOnTIpt79+/c1dOhQFSxYUJ6ensqaNauqVaumVatWPbGNJ3l0TlDc38jhw4fVunVrZc6cWdWqVZP0dJ9NSVG0aFFly5ZNp06dsiqPiorS4MGDVaBAAXl4eCggIEB9+/a1+Rx/VGI/v57G9evX1adPH5UsWVIZMmRQxowZVb9+fe3fv99SJzIyUt7e3urevbvN/v/8849cXV0VEhJiKbt586Z69OihgIAAeXh4qECBAho9erTVKJuH/0YnTJhgea0+b8OEUxN6gtK4uXPn6o033pC7u7tatWqlqVOnaufOnVbd5ZGRkapevbqOHDmijh076sUXX9S1a9f066+/6p9//lHRokX1+eefa9CgQfrggw9UvXp1SfEPbUiXLp2aNWumxYsXa/r06VZXJ5YuXaqoqCjL+OSIiAh99913atWqld5//33dunVLM2bMUL169bRjxw6VKVNGfn5+mjp1qj788EM1a9ZMb7zxhiSpVKlSCT7m9957T7Nnz9Zbb72l3r17a/v27QoJCdGRI0e0ZMkSq7onT57UW2+9peDgYLVr104zZ85U+/btVa5cORUvXtzu854nTx7VqFFD69atU0REhDJmzBhvvTfffFOHDh3Sxx9/rMDAQF25ckWrVq3S+fPnFRgYqAkTJujjjz9WhgwZNGDAAElS9uzZrY7x0Ucfyc/PT4MGDdLt27cfG9eJEyfUokULde7cWe3atdOsWbPUvHlz/fnnn6pTp06SHmNiYntYaGioOnTooAoVKigkJESXL1/WxIkTtWXLFu3du1eZMmWy1I2NjVW9evVUqVIlffnll1q9erXGjh2r/Pnz68MPP0ywjerVq2v8+PE6dOiQSpQoIUnatGmTXFxctGnTJnXr1s1SJj0YIhafTp066eLFi1q1apW+//77eOvMmzdPt27dUqdOnWQymfTFF1/ojTfe0OnTpx/bO/rbb7/J09NTb7/9drzbg4KCVK1aNa1du1Z3796Vl5eXZVvXrl2VKVMmDRkyRMeOHdPUqVN17tw5S4KT1OdEetAz1ahRI7Vs2VLNmzfX1KlT1bJlS82dO1c9evRQ586d1bp1a40ZM0ZvvfWWLly4IB8fH0nSzp07tXXrVrVs2VK5c+fW2bNnNXXqVNWsWVOHDx9W+vTpH9t2fOcmMDDQ8h7zqJdfflmBgYH67bffNGXKlCQdW5KmTp2q4sWL6/XXX5ebm5t+++03ffTRRzKbzerSpYtV3Se9N7z88svq1q2bvvrqK3366acqWrSoJFn+fdSjQ8Ykafz48dq3b5+yZs0qKXHnM6nt3r17VzVr1tTJkyfVtWtXBQUFadGiRWrfvr1u3rxp8yXN3td1UiW2nZiYGNWrV0/VqlXTl19+aXlNderUyfKe0q1bN505c0aTJ0/W3r17tWXLFqVLl05XrlxR3bp15efnp379+ilTpkw6e/aszYWfxMazevVq1a9fX/ny5dOQIUN09+5dTZo0SVWrVtWePXseu0DQoEGDNHz4cDVo0EANGjTQnj17VLduXUVHR1vVGzJkiEJCQvTee++pYsWKioiI0K5du7Rnz55EvUffunXLZj5LlixZ5OKS8DXv5s2bq2DBgho5cqTlAlJyfDYlRnh4uG7cuGF1QchsNuv111/X5s2b9cEHH6ho0aL6+++/NX78eB0/flxLly5NcjvJ6fTp01q6dKmaN2+uoKAgXb58WdOnT1eNGjV0+PBh5cqVSxkyZFCzZs20YMECjRs3zmpkxo8//ijDMCwJ/Z07d1SjRg39+++/6tSpk/LkyaOtW7eqf//+CgsL04QJE6zanzVrlu7du6cPPvhAHh4eypIly7N8+GmLgTRr165dhiRj1apVhmEYhtlsNnLnzm10797dqt6gQYMMScbixYttjmE2mw3DMIydO3cakoxZs2bZ1GnXrp2RN29ey/0VK1YYkozffvvNql6DBg2MfPnyWe7HxMQYUVFRVnVu3LhhZM+e3ejYsaOl7OrVq4YkY/DgwTZtDx482Hj4Zbxv3z5DkvHee+9Z1evTp48hyVi7dq2lLG/evIYkY+PGjZayK1euGB4eHkbv3r1t2nqUJKNLly4Jbu/evbshydi/f79hGIZx5swZq3N448YNQ5IxZsyYx7ZTvHhxo0aNGjbls2bNMiQZ1apVM2JiYuLddubMGUtZ3OP9+eefLWXh4eFGzpw5jbJly1rKHj2njztmQrGtW7fOkGSsW7fOMAzDiI6ONvz9/Y0SJUoYd+/etdRbtmyZIckYNGiQpaxdu3aGJOPzzz+3OmbZsmWNcuXK2bT1sCtXrhiSjClTphiGYRg3b940XFxcjObNmxvZs2e31OvWrZuRJUsWy+v70efGMAyjS5cu8Z6HuLpZs2Y1rl+/bin/5Zdf4n3dPypTpkxG6dKlH1unW7duhiTjwIEDhmH837kvV66cER0dban3xRdfGJKMX375xVKW2OfEMAyjRo0ahiRj3rx5lrKjR48akgwXFxfjr7/+spTH/V0/fI7u3Llj0862bdsMScacOXMe2/ajbt68aUgymjRpkmAdwzCM119/3ZBkREREGIZh+/4TJ77XcXzx1qtXz+p9yTAS/96waNGiBB9XjRo14n0e4ixcuNDmdZ7Y85mUdidMmGBIMn744QdLWXR0tFG5cmUjQ4YMlvP4tK/rh40ZM8bmvSJOUtqJey/o16+f1TE2bdpkSDLmzp1rVf7nn39alS9ZssSQZOzcuTPBWJMST5kyZQx/f3/jv//+s5Tt37/fcHFxMd59911L2aPvlVeuXDHc3d2Nhg0bWt5zDMMwPv30U0OS0a5dO0tZ6dKljYYNGyYYb0Li/sbiu8XF8ejnaNzfSKtWrayO9bSfTQmRZAQHBxtXr141rly5Yuzatct47bXXbNr6/vvvDRcXF2PTpk1W+0+bNs2QZGzZssVSljdvXqvzl5TPr/jE7X/16tUE69y7d8+IjY21Kjtz5ozh4eFh9fcc9565fPlyq7qlSpWyOm/Dhg0zvL29jePHj1vV69evn+Hq6mqcP3/e0oYkI2PGjMaVK1ce+ziQOAyHS8Pmzp2r7Nmzq1atWpIedIW3aNFC8+fPtxpW9PPPP6t06dJq1qyZzTHsWX76lVdeUbZs2bRgwQJL2Y0bN7Rq1Sq1aNHCUubq6mrpKTKbzbp+/bpiYmJUvnx57dmzJ8ntSg8m5EqyWpBAknr37i1JNqvQFCtWzOqqs5+fnwoXLqzTp0/b1f7DMmTIIOnBlbn4eHl5yd3dXevXr7cZwpEU77//fqLn/+TKlcvqeY4bUrV3715dunTJ7hieZNeuXbpy5Yo++ugjq3HpDRs2VJEiReJdHahz585W96tXr/7E58XPz09FihTRxo0bJT1YgMDV1VWffPKJLl++rBMnTkh60BNUrVq1p1pevUWLFsqcObNVfJKeGOOtW7csPSkJidseERFhVf7BBx9YXSX/8MMP5ebmZnnd2yNDhgxWq0cVLlxYmTJlUtGiRa1WlIz7/8OP7+Feqvv37+u///5TgQIFlClTpiT/Dcf9nST23CT0d/U4D8cbHh6ua9euqUaNGjp9+rTCw8Ot6qbke8Phw4fVsWNHNWnSRJ999lm88T3t+Yzzxx9/KEeOHGrVqpWlLF26dOrWrZsiIyO1YcMGq/r2vq6TKintPNr7u2jRIvn6+qpOnTq6du2a5VauXDllyJDBMqQ6rnd52bJlun///lPFExYWpn379ql9+/ZWV95LlSqlOnXqPPZvcPXq1YqOjrYMzY3To0cPm7qZMmXSoUOHLO9VSTVo0CCtWrXK6pYjR47H7vPoe21yfTbFZ8aMGfLz85O/v7/Kly+vNWvWqG/fvlaf2YsWLVLRokVVpEgRq+f3lVdekSSrIfOO4OHhYelZi42N1X///acMGTKocOHCVn+ntWvXVq5cuaymIRw8eFAHDhywmhe1aNEiVa9eXZkzZ7Z6vLVr11ZsbKzl8yzOm2++aTNcGPZJM0nQxo0b1bhxY+XKlUsmk8mu7lLDMPTll1+qUKFC8vDw0AsvvGA1pyM1iY2N1fz581WrVi2dOXNGJ0+e1MmTJ1WpUiVdvnxZa9assdQ9deqUZehQcnBzc9Obb76pX375xTJ+d/Hixbp//75VEiRJs2fPVqlSpSxjn/38/PT777/bfCFJrHPnzsnFxcVmBbwcOXIoU6ZMOnfunFV5njx5bI6ROXPmZHnjjxv6ktCXOg8PD40ePVrLly9X9uzZ9fLLL+uLL75IcjKSlAniBQoUsPniX6hQIUlPP2H5ceLOe+HChW22FSlSxOZ58fT0tHmTT+zzUr16dctwt02bNql8+fIqX768smTJok2bNikiIkL79+9PcMhVYj362on7AvWkGH18fJ74BT6hhKBgwYJW9zNkyKCcOXM+1XOXO3dum9eEr6+vAgICbMok68d39+5dDRo0yDKOPVu2bPLz89PNmzeT/Dec2OTm1q1bMplMVquOJdaWLVtUu3Zty3wOPz8/ffrpp5JkE29KvTdERETojTfe0AsvvKA5c+ZYnfvkPJ9xzp07p4IFC9oMh4obPvek98TEvq6TKrHtuLm5WeY6xjlx4oTCw8Pl7+8vPz8/q1tkZKSuXLkiSapRo4befPNNDR06VNmyZVOTJk00a9aseOeVPCmex72HFS1aVNeuXUtwOHLcvo/+/fr5+VklXpL0+eef6+bNmypUqJBKliypTz75RAcOHIj3uPEpWbKkateubXV70oIIj36GJNdnU3yaNGmiVatW6ffff7fM37lz547V6/PEiRM6dOiQzXMb91kV9/w6itls1vjx41WwYEGrv9MDBw5Y/Z26uLioTZs2Wrp0qe7cuSPpwcVpT09Py7w+6cHj/fPPP20eb+3atSXZPt7nfVGY1CTNzAm6ffu2SpcurY4dO1rmjSRV9+7dtXLlSn355ZcqWbKkrl+/ruvXrydzpM/G2rVrFRYWpvnz52v+/Pk22+fOnau6deumWPstW7bU9OnTtXz5cjVt2lQLFy5UkSJFVLp0aUudH374Qe3bt1fTpk31ySefyN/f3zJZ8NFJkkmV2Cv8CfWgGA9NrLfXwYMH5erq+tg3rB49eqhx48ZaunSpVqxYoYEDByokJERr165V2bJlE9XOw1ePk0NC5+5JixIkp6dZ2a5atWr69ttvdfr0aW3atEnVq1eXyWRStWrVtGnTJuXKlUtms/mpkyB7XztFixbV3r17FRUVleAS5gcOHFC6dOlsvjSlhIQeR2Ie38cff6xZs2apR48eqly5snx9fS2/S5LUZfN9fX2VK1euJ37hO3DggHLnzm3pRU7s6/XUqVN69dVXVaRIEY0bN04BAQFyd3fXH3/8ofHjx9vEm1LvDe3bt9fFixe1Y8cOm7mCyXk+7ZWS74n2tPPwVfc4ZrNZ/v7+CS70E3cBxWQy6aefftJff/2l3377TStWrFDHjh01duxY/fXXX5be+qTEk9JefvllnTp1Sr/88otWrlyp7777TuPHj9e0adP03nvvpUib8X2GJMdnU3xy585t+XLfoEEDZcuWTV27dlWtWrUs393MZrNKliypcePGxXuMRy/QPOxZfH6NHDlSAwcOVMeOHTVs2DDLnKsePXrY/J2+++67GjNmjJYuXapWrVpp3rx5atSokeWikvTg8dapU0d9+/aNt7245C9Ocn/mO7M0kwTVr19f9evXT3B7VFSUBgwYoB9//FE3b95UiRIlNHr0aMtqJkeOHNHUqVN18OBBy5We1Jxtz507V/7+/pYVrh62ePFiLVmyRNOmTZOXl5fy58+vgwcPPvZ4SR029PLLLytnzpxasGCBZZJ33OTJOD/99JPy5cunxYsXWx3/0SW8k9J23rx5ZTabdeLECauJwpcvX9bNmzeVN2/eJD0Oe50/f14bNmxQ5cqVnzi8J3/+/Ordu7d69+6tEydOqEyZMho7dqx++OEHSfYNSUzIyZMnZRiG1TGPHz8u6f9+SyLuyuTNmzetFit49IpxUmKLO+/Hjh2zDGmIc+zYsWR9XuKSm1WrVmnnzp2W35F6+eWXNXXqVOXKlUve3t4qV67cY4+TnOf9YY0aNdK2bdu0aNEim+XVpQc9cps2bVLt2rVtPuxOnDhhGd4qPehtDAsLsyzDnpJxx+enn35Su3btNHbsWEvZvXv3dPPmTbuO17hxY02fPl2bN2+2rFL1sE2bNuns2bNWQ2cyZ84cb3uPvl5/++03RUVF6ddff7W66v80Q2uSeq5HjRqlpUuXavHixSpSpIjN9sSez6S+Jx44cEBms9kqmTh69Khle2qTP39+rV69WlWrVk3UF8KXXnpJL730kkaMGKF58+apTZs2mj9/fpKSioffwx519OhRZcuWLcGlpeP2PXHihPLly2cpv3r1arw9bHErrHbo0EGRkZF6+eWXNWTIkBRLghLyLD6bOnXqpPHjx+uzzz5Ts2bNZDKZlD9/fu3fv1+vvvpqkttIyueXvX766SfVqlVLM2bMsCq/efOmTQ91iRIlVLZsWc2dO1e5c+fW+fPnNWnSJKs6+fPnV2RkpCU5xLOTZobDPUnXrl21bds2zZ8/XwcOHFDz5s312muvWcbd/vbbb8qXL5+WLVumoKAgBQYG6r333kuVPUF3797V4sWL1ahRI7311ls2t65du+rWrVv69ddfJT0YX7p//36bldOk/7sKFvfmntgvNy4uLnrrrbf022+/6fvvv1dMTIzNULi4K28PX2nbvn27tm3bZlUvbjWgxLQd92Xw0dVU4q4oNWzYMFHxP43r16+rVatWio2NtUn8Hnbnzh3du3fPqix//vzy8fGxGq7h7e1t95fKR128eNHqeY6IiNCcOXNUpkwZy7jxuFV6Hh6HfPv2bZsldZMSW/ny5eXv769p06ZZPbbly5fryJEjyfq8BAUF6YUXXtD48eN1//59Va1aVdKD5OjUqVP66aef9NJLLz3x96WS+ppPrE6dOsnf31+ffPKJzfyHe/fuqUOHDjIMQ4MGDbLZ95tvvrGa2zB16lTFxMRYXQBKztfLk7i6utpcKZ80aZLdV1379Omj9OnTq1OnTvrvv/+stl2/fl2dO3dWxowZ1bVrV0t5/vz5FR4ebtWDFBYWZvN+Ft/7TXh4uGbNmmVXrFLSXiOrV6/WZ599pgEDBtj8rs7DMSbmfCal3QYNGujSpUtWczRjYmI0adIkZciQQTVq1HjiMZ43b7/9tmJjYzVs2DCbbTExMZbzcuPGDZvzGfdj309aavlROXPmVJkyZTR79myr837w4EGtXLnS6kLEo2rXrq106dJp0qRJVvE8+jklyeZ1nyFDBhUoUCDJ8T6NZ/nZ5Obmpt69e+vIkSP65ZdfJD14fv/99199++23NvXv3r372FVQk/L5Za/4/k4XLVpk83MPcd555x2tXLlSEyZMUNasWW0u2L/99tvatm2bVqxYYbPvzZs3FRMTk2yxw1qa6Ql6nPPnz2vWrFk6f/68cuXKJenBh+2ff/6pWbNmaeTIkTp9+rTOnTunRYsWac6cOYqNjVXPnj311ltvae3atQ5+BEnz66+/6tatW3r99dfj3f7SSy/Jz89Pc+fOVYsWLfTJJ5/op59+UvPmzdWxY0eVK1dO169f16+//qpp06apdOnSyp8/vzJlyqRp06bJx8dH3t7eqlSp0mN7y1q0aKFJkyZp8ODBKlmypM0Sro0aNdLixYvVrFkzNWzYUGfOnNG0adNUrFgxq6Vkvby8VKxYMS1YsECFChVSlixZVKJEiXjnMZUuXVrt2rXTN998o5s3b6pGjRrasWOHZs+eraZNm1pdRU8Ox48f1w8//CDDMCxzTRYtWqTIyEiNGzdOr7322mP3ffXVV/X222+rWLFicnNz05IlS3T58mWrierlypXT1KlTNXz4cBUoUED+/v42vSmJVahQIQUHB2vnzp3Knj27Zs6cqcuXL1t9Eaxbt67y5Mmj4OBgffLJJ3J1ddXMmTPl5+en8+fPWx0vsbGlS5dOo0ePVocOHVSjRg21atXKskR2YGCgevbsadfjSUj16tU1f/58lSxZ0nJl8MUXX5S3t7eOHz+u1q1bP/EYcT1F3bp1U7169eTq6mr1vNgra9as+umnn9SwYUO9+OKLeu+991SsWDFdunRJoaGhOnnypCZOnBjvEvTR0dGW18yxY8c0ZcoUVatWzepvPTlfL0/SqFEjff/99/L19VWxYsW0bds2rV692rLkc1IVKFBAc+bMUatWrVSyZEkFBwcrKChIZ8+e1YwZM3Tjxg3Nnz/f6n2nZcuW+t///qdmzZqpW7duunPnjqZOnapChQpZTVKuW7eu3N3d1bhxY3Xq1EmRkZH69ttv5e/vr7CwMLviLVOmjFxdXTV69GiFh4fLw8PD8jtEj2rVqpX8/PxUsGBBy5X0OHXq1FH27NkTfT6T0u4HH3yg6dOnq3379tq9e7cCAwP1008/acuWLZowYcITe6qfRzVq1FCnTp0UEhKiffv2qW7dukqXLp1OnDihRYsWaeLEiXrrrbc0e/ZsTZkyRc2aNVP+/Pl169Ytffvtt8qYMeNjk5aEjBkzRvXr11flypUVHBxsWSLb19fX6vd3HhX3O2chISFq1KiRGjRooL1792r58uU2PQfFihVTzZo1Va5cOWXJkkW7du3STz/9ZJX4p7Rn/dnUvn17DRo0SKNHj1bTpk31zjvvaOHChercubPWrVunqlWrKjY2VkePHtXChQu1YsUKlS9fPt5jJeXz63HGjRtns8S/i4uLPv30UzVq1Eiff/65OnTooCpVqujvv//W3LlzrXr5Hta6dWv17dtXS5Ys0Ycffmiz1Pwnn3yiX3/9VY0aNbIsw3/79m39/fff+umnn3T27Fm75kAiEZ7xanTPhCRjyZIllvtxy/B6e3tb3dzc3Iy3337bMAzDeP/99w1JxrFjxyz77d6925BkHD169Fk/hKfSuHFjw9PT07h9+3aCddq3b2+kS5fOuHbtmmEYhvHff/8ZXbt2NV544QXD3d3dyJ07t9GuXTvLdsN4sGRosWLFDDc3N6ulchNaotZsNhsBAQGGJGP48OHxbh85cqSRN29ew8PDwyhbtqyxbNmyeI+3detWo1y5coa7u7vVMp/xLYd5//59Y+jQoUZQUJCRLl06IyAgwOjfv79x7949q3p58+aNdynSJy1tG0cPLUHq4uJiZMqUyShbtqzRvXt349ChQzb1H12G+dq1a0aXLl2MIkWKGN7e3oavr69RqVIlY+HChVb7Xbp0yWjYsKHh4+NjSLLEFrfkZ3zLvya0RHbDhg2NFStWGKVKlTI8PDyMIkWKGIsWLbLZf/fu3UalSpUMd3d3I0+ePMa4cePiPWZCsSW0JPKCBQuMsmXLGh4eHkaWLFmMNm3aGP/8849VnXbt2hne3t42MSW09Gl8vv76a0OS8eGHH1qV165d25BkrFmzxqo8viWyY2JijI8//tjw8/MzTCaTpe24uvEtH/vwa/NJzpw5Y7z//vtGnjx5jHTp0hnZsmUzXn/9dZtlYQ3j/57PDRs2GB988IGROXNmI0OGDEabNm2slus1jKQ9JzVq1DCKFy9u015Cfxt6ZFn4GzduGB06dDCyZctmZMiQwahXr55x9OhRm2VrE7NE9sP+/vtvo3Xr1kaOHDkMFxcXQ5Lh6ekZ79+VYRjGypUrjRIlShju7u5G4cKFjR9++CHe18uvv/5qlCpVyvD09DQCAwON0aNHGzNnzkzwb+VR8b03fPvtt0a+fPkMV1dXq8f4aN2H3y8evcXtk9jzmZR2DcMwLl++bDmuu7u7UbJkSZufO0iu17VhJG6J7MS0k9B7QZxvvvnGKFeunOHl5WX4+PgYJUuWNPr27WtcvHjRMAzD2LNnj9GqVSsjT548hoeHh+Hv7280atTI2LVrl92Pe/Xq1UbVqlUNLy8vI2PGjEbjxo2Nw4cPW9WJ770yNjbWGDp0qJEzZ07Dy8vLqFmzpnHw4EGb53b48OFGxYoVjUyZMhleXl5GkSJFjBEjRlgtjR+fuL+x+N7PE3o8CS0H/bSfTY9rP6GflRgyZIjV6zg6OtoYPXq0Ubx4ccPDw8PInDmzUa5cOWPo0KFGeHi4Zb/4/jYS+/kVn7hzEt/N1dXVMIwHS2T37t3b8lxWrVrV2LZt22O/OzRo0MCQZGzdujXe7bdu3TL69+9vFChQwHB3dzeyZctmVKlSxfjyyy8tz/3jXquwj8kwnvGsv2fAZDJpyZIlliEHCxYsUJs2bXTo0CGbyY8ZMmRQjhw5NHjwYI0cOdJqqMndu3eVPn16rVy5Msk/JAkAySXuRyF37tyZ4BXQtGzOnDlq37692rZtqzlz5jg6HABIkmbNmunvv//WyZMnHR0KHuIUw+HKli2r2NhYXblyJcEVoapWraqYmBidOnXKMqY0bsJ4apw4CgBpxbvvvquwsDD169dPuXPn1siRIx0dEgAkSlhYmH7//ffHzhGGY6SZnqDIyEhLhl22bFmNGzdOtWrVUpYsWZQnTx61bdtWW7Zs0dixY1W2bFldvXpVa9asUalSpdSwYUOZzWZVqFBBGTJk0IQJE2Q2m9WlSxdlzJhRK1eudPCjA+DMnL0nCABSmzNnzmjLli367rvvtHPnTp06deqJP1yLZyvNrA63a9culS1b1rJ+fa9evVS2bFnLCkuzZs3Su+++q969e6tw4cJq2rSpdu7caVkq1cXFRb/99puyZcuml19+WQ0bNlTRokXj/Y0dAAAAICEbNmzQO++8ozNnzmj27NkkQM+hNNMTBAAAAACJkWZ6ggAAAAAgMUiCAAAAADiVVL06nNls1sWLF+Xj4yOTyeTocAAAAAA4iGEYunXrlnLlyiUXl8f39aTqJOjixYsKCAhwdBgAAAAAnhMXLlxQ7ty5H1snVSdBPj4+kh480IwZMzo4GgAAAMC5lBqyQmZDcjFJB4bUc2gsERERCggIsOQIj5Oqk6C4IXAZM2YkCQIAAACeMReP9NL/T4Kel+/jiZkmw8IIAAAAAJwKSRAAAAAAp0ISBAAAAMCppOo5QQCSV2xsrO7fv+/oMADAqbi6usrNzY2f+0CqtOzjarofa1Y619TVt0ISBECSFBkZqX/++UeGYTg6FABwOunTp1fOnDnl7u7u6FCAJCmWy9fRIdiFJAiAYmNj9c8//yh9+vTy8/PjaiQAPCOGYSg6OlpXr17VmTNnVLBgwSf+yCOAp0cSBED379+XYRjy8/OTl5eXo8MBAKfi5eWldOnS6dy5c4qOjpanp6ejQwLSPJIgABb0AAGAY9D7g9Sqx/x9ioy6rwwe6TShZRlHh5NoJEEAAAAA7PLr/n9l/v8/lpqakiAuOwAAAABwKvQEAUjQ+FXHn2l7PesUeqbtnT17VkFBQdq7d6/KlCmTqH1CQ0PVo0cP3bx506FxAAAA+9ETBCDVu3Dhgjp27KhcuXLJ3d1defPmVffu3fXff/89dr+AgACFhYWpRIkSiW6rRYsWOn782SaHAAAgeZEEAUjVTp8+rfLly+vEiRP68ccfdfLkSU2bNk1r1qxR5cqVdf369Xj3i46Olqurq3LkyCE3t8R3int5ecnf3z+5wgcAAA5AEgQgVevSpYvc3d21cuVK1ahRQ3ny5FH9+vW1evVq/fvvvxowYIAkKTAwUMOGDdO7776rjBkz6oMPPtDZs2dlMpm0b98+y/F+/fVXFSxYUJ6enqpVq5Zmz54tk8lkGf4WGhqqTJkyWeoPGTJEZcqU0ffff6/AwED5+vqqZcuWunXrlqXOn3/+qWrVqilTpkzKmjWrGjVqpFOnTj2L0wMAAOJBEgQg1bp+/bpWrFihjz76yOb3jXLkyKE2bdpowYIFMgxDkvTll1+qdOnS2rt3rwYOHGhzvDNnzuitt95S06ZNtX//fnXq1MmSRD3OqVOntHTpUi1btkzLli3Thg0bNGrUKMv227dvq1evXtq1a5fWrFkjFxcXNWvWTGaz+SnPAAAAsAcLIwBItU6cOCHDMFS0aNF4txctWlQ3btzQ1atXJUmvvPKKevfubdl+9uxZq/rTp09X4cKFNWbMGElS4cKFdfDgQY0YMeKxcZjNZoWGhsrHx0eS9M4772jNmjWW/d58802r+jNnzpSfn58OHz6cpPlIAAAgedATBCDVi+vpeZLy5cs/dvuxY8dUoUIFq7KKFSs+8biBgYGWBEiScubMqStXrljunzhxQq1atVK+fPmUMWNGBQYGSpLOnz+fqLgBAEDyIgkCkGoVKFBAJpNJR44ciXf7kSNHlDlzZvn5+UmSvL29UySOdOnSWd03mUxWQ90aN26s69ev69tvv9X27du1fft2SQ8WZwAAIDXL4OEmd1cXZfBIXQPMHJoExcbGauDAgQoKCpKXl5fy58+vYcOGJfqqLgDnljVrVtWpU0dTpkzR3bt3rbZdunRJc+fOVYsWLWQymRJ1vMKFC2vXrl1WZTt37nyqGP/77z8dO3ZMn332mV599VXLED0AANKCA0Pq6fiI+jowpJ6jQ0kSh6Zso0eP1tSpUzV79mwVL15cu3btUocOHeTr66tu3bo5MjS7JPTDks/6ByABZzJ58mRVqVJF9erV0/DhwxUUFKRDhw7pk08+0QsvvPDE+TwP69Spk8aNG6f//e9/Cg4O1r59+xQaGipJiU6kHpU5c2ZlzZpV33zzjXLmzKnz58+rX79+dh0LAAAkD4cmQVu3blWTJk3UsGFDSQ/G1f/444/asWOHI8MC8P+lhgS+YMGC2rVrlwYPHqy3335b169fV44cOdS0aVMNHjxYWbJkSfSxgoKC9NNPP6l3796aOHGiKleurAEDBujDDz+Uh4eHXfG5uLho/vz56tatm0qUKKHChQvrq6++Us2aNe06HgAAeHomw4Fjz0aOHKlvvvlGK1euVKFChbR//37VrVtX48aNU5s2bWzqR0VFKSoqynI/IiJCAQEBCg8PV8aMGZ9l6PGiJwip1b1793TmzBkFBQXJ09PT0eE8V0aMGKFp06bpwoULjg4FQBrG+zDw9CIiIuTr65uo3MChPUH9+vVTRESEihQpIldXV8XGxmrEiBHxJkCSFBISoqFDhz7jKAE4kylTpqhChQrKmjWrtmzZojFjxqhr166ODgsAgOdStdFrFRkVowwebtr8v1ccHU6iOTQJWrhwoebOnat58+apePHi2rdvn3r06KFcuXKpXbt2NvX79++vXr16We7H9QQBQHI5ceKEhg8fruvXrytPnjzq3bu3+vfv7+iwAAB4Ll28eVdmQ4q4e9/RoSSJQ5OgTz75RP369VPLli0lSSVLltS5c+cUEhISbxLk4eFh97h8AEiM8ePHa/z48Y4OAwAApCCHLpF9584dubhYh+Dq6mr1+xoAAAAAkJwc2hPUuHFjjRgxQnny5FHx4sW1d+9ejRs3Th07dnRkWAAAAADSMIcmQZMmTdLAgQP10Ucf6cqVK8qVK5c6deqkQYMGOTIsAAAAAGmYQ5MgHx8fTZgwQRMmTHBkGAAAAACciEPnBAEAAADAs0YSBAAAAMCpkAQBQApbv369TCaTbt68maLtBAYGMrz4KdWsWVM9evRI9uMOGTJEZcqUSfbjAgDsQxIEIFW7cOGCOnbsqFy5csnd3V158+ZV9+7d9d9//zkknvi+RFepUkVhYWHy9fVNljZCQ0OVKVMmm/KdO3fqgw8+SJY24rRv314mk8nm9tprryVrO4mNo3PnzjbbunTpIpPJpPbt2yf6eM8qMU2ss2fPymQyydXVVf/++6/VtrCwMLm5uclkMuns2bOW8iVLluill16Sr6+vfHx8VLx4cavXXmhoaLzPnaenZ5Jii42N1cCBAxUUFCQvLy/lz59fw4YNk2EYj91v/fr1evHFF+Xh4aECBQooNDTUps7XX3+twMBAeXp6qlKlStqxY0eSYgPgeBWDsqh4royqGJTF0aEkCUkQgFTr9OnTKl++vE6cOKEff/xRJ0+e1LRp07RmzRpVrlxZ169fd3SIkiR3d3flyJFDJpMpRdvx8/NT+vTpk/24r732msLCwqxuP/74Y4L179+3/dXw6Ohou9p+eL+AgADNnz9fd+/etZTdu3dP8+bNU548eew6/vPmhRde0Jw5c6zKZs+erRdeeMGqbM2aNWrRooXefPNN7dixQ7t379aIESNszn3GjBltnrtz584lKabRo0dr6tSpmjx5so4cOaLRo0friy++0KRJkxLc58yZM2rYsKFq1aqlffv2qUePHnrvvfe0YsUKS50FCxaoV69eGjx4sPbs2aPSpUurXr16unLlSpLiA+BY8z+orN+7Vdf8Dyo7OpQkIQkCkGp16dJF7u7uWrlypWrUqKE8efKofv36Wr16tf79918NGDDAUtdkMmnp0qVW+2fKlMnq6vT//vc/FSpUSOnTp1e+fPk0cOBAqy+VcUOavv/+ewUGBsrX11ctW7bUrVu3JD3ordiwYYMmTpxouep+9uxZm16HmjVrxnuFPu4q/7hx41SyZEl5e3srICBAH330kSIjIyU9uLreoUMHhYeHW/YbMmSIJNvhcOfPn1eTJk2UIUMGZcyYUW+//bYuX76c6McTx8PDQzly5LC6Zc6c2ercTp06Va+//rq8vb01YsQIy7G/++47BQUFWXofEhvTo/tJ0osvvqiAgAAtXrzYUrZ48WLlyZNHZcuWtYrZbDYrJCTE0ntRunRp/fTTT5Ie9LrUqlVLkpQ5c2abXiSz2ay+ffsqS5YsypEjh+X8Jva8StKoUaOUPXt2+fj4KDg4WPfu3VNitGvXTrNmzbIqmzVrltq1a2dV9ttvv6lq1ar65JNPVLhwYRUqVEhNmzbV119/bVXPZDLZPHfZs2dPVCxxtm7dqiZNmqhhw4YKDAzUW2+9pbp16z6212batGkKCgrS2LFjVbRoUXXt2lVvvfWWxo8fb6kzbtw4vf/+++rQoYOKFSumadOmKX369Jo5c2aS4gMAe5AEAUjQd5tO66WRa554e2/2Tpt935u9M1H7frfptF2xXb9+XStWrNBHH30kLy8vq205cuRQmzZttGDBgicO2XmYj4+PQkNDdfjwYU2cOFHffvut1Zc2STp16pSWLl2qZcuWadmyZdqwYYNGjRolSZo4caIqV66s999/33LVPSAgwKadxYsXW12Zf+ONN1S4cGHLl1MXFxd99dVXOnTokGbPnq21a9eqb9++kh4MrZswYYLVFf4+ffrYtGE2m9WkSRNdv35dGzZs0KpVq3T69Gm1aNEi0Y8nKYYMGaJmzZrp77//tvzg9cmTJ/Xzzz9r8eLF2rdvX6JjenS/h3Xs2NEqSZg5c6Y6dOhgE09ISIjmzJmjadOm6dChQ+rZs6fatm2rDRs2KCAgQD///LMk6dixYwoLC9PEiRMt+86ePVve3t7avn27vvjiC33++edatWpVos/rwoULNWTIEI0cOVK7du1Szpw5NWXKlESdx9dff103btzQ5s2bJUmbN2/WjRs31LhxY6t6OXLk0KFDh3Tw4MFEHTchcUPmHqdKlSpas2aNjh8/Lknav3+/Nm/erPr16ye4z7Zt21S7dm2rsnr16mnbtm2SHvTw7d6926qOi4uLateubakDACnJob8TBOD5dutejC5FPPkKds5MtnMM/rsdnah9b92LsSu2EydOyDAMFS1aNN7tRYsW1Y0bN3T16lX5+/sn6pifffaZ5f+BgYHq06eP5s+fb0lApAdfgkNDQ+Xj4yNJeuedd7RmzRqNGDFCvr6+cnd3V/r06ZUjR44E28mS5f/GTY8fP15r167V9u3bLcncw/M6AgMDNXz4cHXu3FlTpkyRu7u7fH19LVf4E7JmzRr9/fffOnPmjCURmzNnjooXL66dO3eqQoUKT3w8cZYtW6YMGTJYHf/TTz/Vp59+arnfunVrm2QkOjpac+bMkZ+fnyRp1apViYrp0f0e1rZtW/Xv398ypGvLli2aP3++1q9fb6kTFRWlkSNHavXq1apc+cHwjHz58mnz5s2aPn26atSoYXkO/P39beZXlSpVSoMHD5YkFSxYUJMnT9aaNWtUp06dRJ3XCRMmKDg4WMHBwZKk4cOHa/Xq1YnqDUqXLp3atm2rmTNnqlq1apo5c6batm2rdOnSWdX7+OOPtWnTJpUsWVJ58+bVSy+9pLp166pNmzby8PCw1AsPD7d57qpXr67ly5dLknx9fVW4cOHHxtSvXz9FRESoSJEicnV1VWxsrEaMGKE2bdokuM+lS5dsepyyZ8+uiIgI3b17Vzdu3FBsbGy8dY4ePfrYeAAgOZAEAUiQj6ebcmR88iTqrN7u8ZYlZl8fz6d7G3pST4+7u21sCVmwYIG++uornTp1SpGRkYqJiVHGjBmt6gQGBloSBknKmTOn3XMYli9frn79+um3335ToUKFLOWrV69WSEiIjh49qoiICMXExOjevXu6c+dOouf8HDlyRAEBAVY9UcWKFVOmTJl05MgRS8KRmMdTq1YtTZ061ars4UROksqXL28TQ968ea0SmcTG9Oh+D/Pz81PDhg0VGhoqwzDUsGFDZcuWzarOyZMndefOHdWpU8eqPDo62mbYXHxKlSpldf/hc5KYx3DkyBGbBRwqV66sdevWPbFt6UFvV5UqVTRy5EgtWrRI27ZtU0yM9cUCb29v/f777zp16pTWrVunv/76S71799bEiRO1bds2y+vEx8dHe/bssdr34Z7TZs2aqVmzZo+NZ+HChZo7d67mzZun4sWLW+b45MqVy2aYHgDnk6//7zIbkotJOh3S0NHhJBpJEIAEvVc9n96rns+ufb9rVyGZo7FWoEABmUwmHTlyJN4vcUeOHJGfn5/lKr/JZLJJmB6e77Nt2za1adNGQ4cOVb169eTr66v58+dr7NixVvs8ekXeZDLJbDYnOf7Dhw+rZcuWGjVqlOrWrWspP3v2rBo1aqQPP/xQI0aMUJYsWbR582YFBwcrOjo62Rc+SMzj8fb2VoECBR57HG9v70SVJcaT9uvYsaO6du0qSTZzYCRZ5k/9/vvvNgsKPNxLkpDkeo7tVbJkSRUpUkStWrVS0aJFVaJECZthgXHy58+v/Pnz67333tOAAQNUqFAhLViwwNIr5+Li8sTn7kk++eQT9evXTy1btrTEd+7cOYWEhCSYBOXIkcNmntTly5eVMWNGeXl5ydXVVa6urvHWeVwPJwAkF+YEAUiVsmbNqjp16mjKlClWq4VJD4bizJ0712qyu5+fn8LCwiz3T5w4oTt37ljub926VXnz5tWAAQNUvnx5FSxYMMmraEkPep5iY2MfW+fatWtq3Lix3nzzTfXs2dNq2+7du2U2mzV27Fi99NJLKlSokC5evJjkNooWLaoLFy7owoULlrLDhw/r5s2bKlasWBIfVfJIrphee+01RUdH6/79+6pXr57N9mLFisnDw0Pnz59XgQIFrG5xPThxPYRPOo/2PIaiRYtq+/btVvv99ddfSWqnY8eOWr9+vWV+VWIEBgYqffr0un37dpLaepI7d+7IxcX664Krq+tjE8PKlStrzZo1VmWrVq2yDE90d3dXuXLlrOqYzWbLyo4AkNJIggCkWpMnT1ZUVJTq1aunjRs36sKFC/rzzz9Vp04dFSpUSIMGDbLUfeWVVzR58mTt3btXu3btUufOna2u+BcsWFDnz5/X/PnzderUKX311VdasmRJkmMKDAzU9u3bdfbsWV27di3eL4pvvvmm0qdPryFDhujSpUuWW2xsrAoUKKD79+9r0qRJOn36tL7//ntNmzbNpo3IyEitWbNG165ds0rm4tSuXVslS5ZUmzZttGfPHu3YsUPvvvuuatSoEe/QtceJioqyivPSpUu6du1a0k5MMsbk6uqqI0eO6PDhw3J1dbXZ7uPjoz59+qhnz56aPXu2Tp06pT179mjSpEmaPXu2pAdD7kwmk5YtW6arV69aeo+S4zF0795dM2fO1KxZs3T8+HENHjxYhw4dsjrOkiVLVKRIkQTbef/993X16lW999578W4fMmSI+vbtq/Xr1+vMmTPau3evOnbsqPv371sNAzQMw+a5u3TpkuV1+aQ4JKlx48YaMWKEfv/9d509e1ZLlizRuHHjrHpg+/fvr3fffddyv3Pnzjp9+rT69u2ro0ePasqUKVq4cKFV0t+rVy99++23mj17to4cOaIPP/xQt2/fjnehCwBIbiRBAFKtggULaufOncqXL5/efvtt5c2bV/Xr11ehQoW0ZcsWqwnhY8eOVUBAgKpXr67WrVurT58+VkPLXn/9dfXs2VNdu3ZVmTJltHXrVg0cODDJMfXp00eurq4qVqyY/Pz8dP78eZs6Gzdu1MGDB5U3b17lzJnTcrtw4YJKly6tcePGafTo0SpRooTmzp2rkJAQq/2rVKmizp07q0WLFvLz89MXX3xh04bJZNIvv/yizJkz6+WXX1bt2rWVL18+LViwIMmP6c8//7SKM2fOnKpWrVqSj5OcMWXMmNFmvtbDhg0bpoEDByokJERFixbVa6+9pt9//11BQUGSHvwez9ChQ9WvXz9lz57dMrwuOR5DixYtNHDgQPXt21flypXTuXPn9OGHH1odJzw8XMeOHUuwHTc3N2XLlk1ubvGPWq9Ro4ZOnz6td999V0WKFFH9+vV16dIlrVy50mqhg4iICJvn7uE5Tk+KQ5ImTZqkt956Sx999JGKFi2qPn36qFOnTho2bJilTlhYmNVrPSgoSL///rtWrVql0qVLa+zYsfruu++seu5atGihL7/8UoMGDVKZMmW0b98+/fnnn0lewhsA7GEykrJ+7HMmIiJCvr6+Cg8Pf+yH4bMyftXxeMt71ikUbznwvLh3757OnDlj87ssqdHgwYM1btw4rVq1Si+99JKjwwGARElL78NwLs/TwghJyQ1YGAFAmjJ06FAFBgbqr7/+UsWKFW3mMgAAAJAEAUhzmFMAAAAeh0ukAAAAAJwKSRAAAAAAp8JwOAAAAAB2GdCgqO7ej5VXOtufLHiekQQBAAAAsEtw9XyODsEuDIcDAAAA4FRIggAAAAA4FYbDAQAAALDLjE2nLXOCUtPQOHqCACCFrV+/XiaTSTdv3kzRdgIDAzVhwoQUbSOtq1mzpnr06JHsxx0yZIjKlCmT7McFAEcb8ccRfbnyuEb8ccTRoSQJSRCAVO3ChQvq2LGjcuXKJXd3d+XNm1fdu3fXf//955B44vsSXaVKFYWFhcnX1zdZ2ggNDVWmTJlsynfu3KkPPvggWdqI0759e5lMJpvba6+9lqztJDaOzp0722zr0qWLTCaT2rdvn+jjPavENLHOnj0rk8kkf39/3bp1y2pbmTJlNGTIEKuyQ4cO6e2335afn588PDxUqFAhDRo0SHfu3LE59t69e9W8eXNlz55dnp6eKliwoN5//30dP37cqu19+/bFG9ujr7fQ0FDL68DFxUW5c+dWhw4ddOXKFUudh18rvr6+qlq1qtauXWvZ3r59ezVt2tTqvslk0qhRo6zaXrp0qUwmk1WZYRj69ttvVblyZWXMmFEZMmRQ8eLF1b17d508eTLex/A4EyZMUOHCheXl5aWAgAD17NlT9+7de+w+Bw4cUPXq1eXp6amAgAB98cUXNnUWLVqkIkWKyNPTUyVLltQff/yR5NgApBySIACp1unTp1W+fHmdOHFCP/74o06ePKlp06ZpzZo1qly5sq5fv+7oECVJ7u7uypEjh82XueTm5+en9OnTJ/txX3vtNYWFhVndfvzxxwTr379/36YsOjrarrYf3i8gIEDz58/X3bt3LWX37t3TvHnzlCdPHruO/7y5deuWvvzyy8fW+euvv1SpUiVFR0fr999/1/HjxzVixAiFhoaqTp06Vuds2bJleumllxQVFaW5c+fqyJEj+uGHH+Tr66uBAwfaHWfGjBkVFhamf/75R99++62WL1+ud955x6rOrFmzFBYWpi1btihbtmxq1KiRTp8+neAxPT09NXr0aN24cSPBOoZhqHXr1urWrZsaNGiglStX6vDhw5oxY4Y8PT01fPjwJD2OefPmqV+/fho8eLCOHDmiGTNmaMGCBfr0008T3CciIkJ169ZV3rx5tXv3bo0ZM0ZDhgzRN998Y6mzdetWtWrVSsHBwdq7d6+aNm2qpk2b6uDBg0mKD0DKIQkCkGp16dJF7u7uWrlypWrUqKE8efKofv36Wr16tf79918NGDDAUtdkMmnp0qVW+2fKlEmhoaGW+//73/9UqFAhpU+fXvny5dPAgQOtvtDHDWn6/vvvFRgYKF9fX7Vs2dJy5b59+/basGGDJk6caLkKfvbsWZteh5o1a8bbu3L27FlJ0rhx41SyZEl5e3srICBAH330kSIjIyU96MHo0KGDwsPDLfvF9RI8Ohzu/PnzatKkiTJkyKCMGTPq7bff1uXLlxP9eOJ4eHgoR44cVrfMmTNbndupU6fq9ddfl7e3t0aMGGE59nfffaegoCB5enomKaZH95OkF198UQEBAVq8eLGlbPHixcqTJ4/Kli1rFbPZbFZISIiCgoLk5eWl0qVL66effpL0oOejVq1akqTMmTPb9CKZzWb17dtXWbJkUY4cOWx6YZ70GCRp1KhRyp49u3x8fBQcHPzEnoU4H3/8scaNG2fVq/IwwzAUHBysokWLavHixapYsaLy5s2r5s2b67ffftO2bds0fvx4SdKdO3fUoUMHNWjQQL/++qtq166toKAgVapUSV9++aWmT5+eqJjiYzKZlCNHDuXKlUv169dXt27dtHr1aqsENVOmTMqRI4dKlCihqVOn6u7du1q1alWCx6xdu7Zy5MihkJCQBOssWLBA8+fP14IFCzRw4EC99NJLypMnj1566SWNHj1as2bNStLj2Lp1q6pWrarWrVsrMDBQdevWVatWrbRjx44E95k7d66io6M1c+ZMFS9eXC1btlS3bt00btw4S52JEyfqtdde0yeffKKiRYtq2LBhevHFFzV58uQkxQcg5ZAEAUjQd5tO66WRa554e2/2Tpt935u9M1H7frcp4SvDj3P9+nWtWLFCH330kby8vKy25ciRQ23atNGCBQtkGEaij+nj46PQ0FAdPnxYEydO1Lfffmv5Qhnn1KlTWrp0qZYtW6Zly5Zpw4YNliE8EydOVOXKlfX+++9bekwCAgJs2lm8eLFVr8obb7yhwoULK3v27JIkFxcXffXVVzp06JBmz56ttWvXqm/fvpIeDK2bMGGC5Up8WFiY+vTpY9OG2WxWkyZNdP36dW3YsEGrVq3S6dOn1aJFi0Q/nqQYMmSImjVrpr///lsdO3aUJJ08eVI///yzFi9erH379iU6pkf3e1jHjh2tvujOnDlTHTp0sIknJCREc+bM0bRp03To0CH17NlTbdu21YYNGxQQEKCff/5ZknTs2DGFhYVp4sSJln1nz54tb29vbd++XV988YU+//xzy5f3xDyGhQsXasiQIRo5cqR27dqlnDlzasqUKYk6j61atVKBAgX0+eefx7t93759Onz4sHr16iUXF+uP8NKlS6t27dqWXroVK1bo2rVrltfOo+IbUmkvLy8vmc1mxcTEJLhdenyPoKurq0aOHKlJkybpn3/+ibfOjz/+qMKFC+v111+Pd/vDva1xFx/iLi7Ep0qVKtq9e7cl6Tl9+rT++OMPNWjQIMF9tm3bppdfflnu7u6Wsnr16unYsWOWXqxt27apdu3aVvvVq1dP27ZtS/C4AJ4tVocDkKBb92J0KeLJV7BzZvK0KfvvdnSi9r11L/4vTU9y4sQJGYahokWLxru9aNGiunHjhq5evSp/f/9EHfOzzz6z/D8wMFB9+vTR/Pnzrb5Ems1mhYaGysfHR5L0zjvvaM2aNRoxYoR8fX3l7u6u9OnTK0eOHAm2kyVLFsv/x48fr7Vr12r79u2WL4oPzykKDAzU8OHD1blzZ02ZMkXu7u7y9fW1XIlPyJo1a/T333/rzJkzlkRszpw5Kl68uHbu3KkKFSo88fHEWbZsmTJkyGB1/E8//dRqyFDr1q1tkpHo6GjNmTNHfn5+kqRVq1YlKqZH93tY27Zt1b9/f507d06StGXLFs2fP1/r16+31ImKitLIkSO1evVqVa5cWZKUL18+bd68WdOnT1eNGjUsz4G/v79NMlCqVCkNHjxYklSwYEFNnjxZa9asUZ06dRJ1XidMmKDg4GAFBwdLkoYPH67Vq1cnqjcobl5M48aN1bNnT+XPn99qe9w8nse97jdv3izpwd+IJBUpUuSJ7T6NEydOaNq0aSpfvrzldfSwO3fu6LPPPpOrq6tq1Kjx2GM1a9ZMZcqU0eDBgzVjxgyb7cePH1fhwoWtynr06KHvvvtO0oPELi6BSp8+vQoXLqx06dIl2F7r1q117do1VatWTYZhKCYmRp07d37scLhLly4pKCjIqizuAsalS5eUOXNmXbp0yVL2cJ1Lly495tEDeJZIggAkyMfTTTky2iY4j8rq7R5vWWL29fF8urehJ/X0PHy19kkWLFigr776SqdOnVJkZKRiYmKUMWNGqzqBgYFWX/Ry5syZ4NClJ1m+fLn69eun3377TYUKFbKUr169WiEhITp69KgiIiIUExOje/fu6c6dO4me83PkyBEFBARY9UQVK1ZMmTJl0pEjRywJR2IeT61atTR16lSrsocTOUkqX768TQx58+a1SmQSG9Oj+z3Mz89PDRs2VGhoqAzDUMOGDZUtWzarOidPntSdO3dUp04dq/Lo6GibYXPxKVWqlNX9h89JYh7DkSNHbBZwqFy5statW/fEtqUHPQbVqlXTwIEDNW/evHjrJKaHMym9oEkVHh6uDBkyyGw26969e6pWrZolEYnTqlUrubq66u7du/Lz89OMGTNszm18Ro8erVdeeSXeHs74DBgwQF27dtXixYs1cuRIS3nFihV19OjRx+67fv16jRw5UlOmTFGlSpV08uRJde/eXcOGDXuqOVMAnn8kQQAS9F71fHrPzjX/v2tXIZmjsVagQAGZTCYdOXJEzZo1s9l+5MgR+fn5Wa7ym0wmmy+FD8/32bZtm9q0aaOhQ4eqXr168vX11fz58zV27FirfR69qmwymWQ2m5Mc/+HDh9WyZUuNGjVKdevWtZSfPXtWjRo10ocffqgRI0YoS5Ys2rx5s4KDgxUdHZ3sCx8k5vF4e3urQIECjz2Ot7d3osoS40n7dezYUV27dpUkff311zbb4+ZP/f7773rhhRestnl4eDyx/eR6jp/GqFGjVLlyZX3yySdW5XHJ8pEjR+JN6I4cOWKpE/fv0aNHLT1iycXHx0d79uyRi4uLcubMaTMkVXrQy1m7dm35+vommNTG5+WXX1a9evXUv39/mxX/ChYsqGPHjlmV+fn5yc/PL9E9vg8bOHCg3nnnHb333nuSpJIlS+r27dv64IMPNGDAAJshh9KD4baPzgGLux/XO5tQncf13gJ4tpgTBCBVypo1q+rUqaMpU6ZYTcaWHgxJmTt3rtUXKD8/P4WFhVnunzhxwmo54a1btypv3rwaMGCAypcvr4IFC1qGXCWFu7u7YmNjH1vn2rVraty4sd5880317NnTatvu3btlNps1duxYvfTSSypUqJAuXryY5DaKFi2qCxcu6MKFC5ayw4cP6+bNmypWrFgSH1XySK6YXnvtNUVHR+v+/fuqV6+ezfZixYrJw8ND58+fV4ECBaxucT04cT2ETzqP9jyGokWLavv27Vb7/fXXX0lqp2LFinrjjTfUr18/q/IyZcqoSJEiGj9+vE1itn//fq1evVqtWrWSJNWtW1fZsmWLd/lmSU+1PLiLi4sKFCigfPnyxZsASQ8SgQIFCiQpAYozatQoy0IPD2vVqpWOHTumX375xa64H3Xnzh2bRMfV1VVSwj1plStX1saNG60uoqxatUqFCxe2LBhSuXJlrVmzxmq/VatWJXsyCsB+JEEAUq3JkycrKipK9erV08aNG3XhwgX9+eefqlOnjuV3U+K88sormjx5svbu3atdu3apc+fOVlf8CxYsqPPnz2v+/Pk6deqUvvrqKy1ZsiTJMQUGBmr79u06e/asrl27Fm8Pwptvvqn06dNryJAhunTpkuUWGxurAgUK6P79+5o0aZJOnz6t77//XtOmTbNpIzIyUmvWrNG1a9fi/W2Y2rVrq2TJkmrTpo327NmjHTt26N1331WNGjXiHbr2OFFRUVZxXrp0SdeuXUvaiUnGmFxdXXXkyBEdPnzY8oX1YT4+PurTp4969uyp2bNn69SpU9qzZ48mTZqk2bNnS3ow5M5kMmnZsmW6evWqpfcoOR5D9+7dNXPmTM2aNUvHjx/X4MGDdejQIavjLFmy5IlzdUaMGKG1a9da9XyYTCbNmDFDhw8f1ptvvqkdO3bo/PnzWrRokRo3bqzKlStb5pR5e3vru+++0++//67XX39dq1ev1tmzZ7Vr1y717dvXZsjesWPHtG/fPqtbfMudPwtx5/irr76yKm/ZsqXeeusttWzZUp9//rnlb23Dhg1asGCB1ethx44dKlKkiP79998E22ncuLGmTp2q+fPn68yZM1q1apUGDhyoxo0bW441efJkvfrqq5Z9WrduLXd3dwUHB+vQoUNasGCBJk6cqF69elnqdO/eXX/++afGjh2ro0ePasiQIdq1a5elBxOA45EEAUi1ChYsqJ07dypfvnx6++23lTdvXtWvX1+FChXSli1brCbzjx07VgEBAapevbpat26tPn36WA0te/3119WzZ0917dpVZcqU0datW+2aE9CnTx+5urqqWLFi8vPz0/nz523qbNy4UQcPHlTevHmVM2dOy+3ChQsqXbq0xo0bp9GjR6tEiRKaO3euzZLBVapUUefOndWiRQv5+fnFe6XfZDLpl19+UebMmfXyyy+rdu3aypcvnxYsWJDkx/Tnn39axZkzZ05Vq1YtycdJzpgyZsxoM1/rYXFzOkJCQlS0aFG99tpr+v333y0T2l944QUNHTpU/fr1U/bs2RP95TQxj6FFixYaOHCg+vbtq3LlyuncuXP68MMPrY4THh5uM6zrUYUKFVLHjh1tFlSoUqWK/vrrL7m6uqp+/foqUKCA+vfvr3bt2mnVqlVWQ/6aNGmirVu3Kl26dGrdurWKFCmiVq1aKTw83OY3dVq2bKmyZcta3R4d0vUsff755zYXEUwmkxYsWKAJEybojz/+0KuvvqrChQurY8eOCggIsCwKIT3o5Tl27NhjE7nPPvtMvXv31meffaZixYopODhY9erVs1o+/Nq1azp16pTlvq+vr1auXKkzZ86oXLly6t27twYNGmT1Q8VVqlTRvHnz9M0331iWZ1+6dKlKlCiRHKcGeK6cDmmos6Ma6nRIQ0eHkiQmIyVnTqawiIgI+fr6Kjw8/LEfhs/K+FXH4y3vWadQvOXA8+LevXs6c+aMze+ypEaDBw/WuHHjtGrVKr300kuODgcAEiUtvQ8DjpKU3ICFEQCkKUOHDlVgYKD++usvVaxYMd6JzQAAwLmRBAFIc+L78UwAAIA4JEEAAAAA7NLym226dS9GPp5umv9B6lkBkSQIAAAAgF12nLkusyG5mBwdSdIwWB6ARSpeJwUAUjXef4FniyQIgOX3MKKjox0cCQA4p7jf+3r498sApByGwwGQm5ub0qdPr6tXrypdunSsqAYAz4hhGLpz546uXLmiTJkyxfsDwACSH0kQAJlMJuXMmVNnzpzRuXPnHB0OADidTJkyKUeOHI4OA3AaJEEAJEnu7u4qWLAgQ+IA4BlLly4dPUDAM+bQJCgwMDDeq84fffSRvv76awdEBDg3FxcXfqkcAACkeQ5Ngnbu3KnY2FjL/YMHD6pOnTpq3ry5A6MCAAAAkJY5NAny8/Ozuj9q1Cjlz59fNWrUcFBEAAAAANK652ZOUHR0tH744Qf16tVLJlP8v7YUFRWlqKgoy/2IiIhnFR4AAACAR+TK5KXIqBhl8Hhu0opEeW6iXbp0qW7evKn27dsnWCckJERDhw59dkEBAAAASNDm/73i6BDs8tz8GMiMGTNUv3595cqVK8E6/fv3V3h4uOV24cKFZxghAAAAgLTguegJOnfunFavXq3Fixc/tp6Hh4c8PDyeUVQAAAAA0qLnoido1qxZ8vf3V8OGDR0dCgAAAIA0zuE9QWazWbNmzVK7du3k5ubwcAAAAAAkUqkhK3Tvvlme6Vx0YEg9R4eTaA7POlavXq3z58+rY8eOjg4FAAAAQBJERsXIbEgxZrOjQ0kShydBdevWlWEYjg4DAAAAgJN4LuYEAQAAAMCzQhIEAAAAwKmQBAEAAABwKiRBAAAAAJwKSRAAAAAAp0ISBAAAAMCpkAQBAAAAcCoO/50gAAAAAKnT66VfUGTUfWXwSOfoUJKEJAgAAACAXSa0LOPoEOzCcDgAAAAAToUkCAAAAIBTYTgcAAAAALscvhiu+7FmpXN1UbFcvo4OJ9FIggAAAADYpdGkzTIbkotJOh3S0NHhJBrD4QAAAAA4FZIgAAAAAE6FJAgAAACAUyEJAgAAAOBUSIIAAAAAOBWSIAAAAABOhSQIAAAAgFMhCQIAAADgVEiCAAAAADgVN0cHAAAAACB1mtm+gqJjzHJ3S119KyRBAAAAAOxSs7C/o0OwS+pK2QAAAADgKZEEAQAAAHAqDIcDAAAAYJeBSw/qdlSMvD3cNKxpCUeHk2gkQQAAAADsMnf7OZkNycWkVJUEMRwOAAAAgFMhCQIAAADgVEiCAAAAADgVkiAAAAAAToUkCAAAAIBTIQkCAAAA4FRIggAAAAA4FZIgAAAAAE6FJAgAAACAXTzcXOVievBvauLm6AAAAAAApE5Hhr3m6BDsQk8QAAAAAKdCEgQAAADAqZAEAQAAAHAqzAkCAAAAYJdXx27Q7aj78vZIpzW9azg6nEQjCQIAAABglzPXImU2JBdTlKNDSRKGwwEAAABwKg5Pgv7991+1bdtWWbNmlZeXl0qWLKldu3Y5OiwAAAAAaZRDh8PduHFDVatWVa1atbR8+XL5+fnpxIkTypw5syPDAgAAAJCGOTQJGj16tAICAjRr1ixLWVBQUIL1o6KiFBX1f+MNIyIiUjQ+AAAAAGmPQ4fD/frrrypfvryaN28uf39/lS1bVt9++22C9UNCQuTr62u5BQQEPMNoAQAAAKQFDk2CTp8+ralTp6pgwYJasWKFPvzwQ3Xr1k2zZ8+Ot37//v0VHh5uuV24cOEZRwwAAAAgtXPocDiz2azy5ctr5MiRkqSyZcvq4MGDmjZtmtq1a2dT38PDQx4eHs86TAAAAABpiEN7gnLmzKlixYpZlRUtWlTnz593UEQAAAAA0jqH9gRVrVpVx44dsyo7fvy48ubN66CIAAAAACRWiRd8detejHw8HZpWJJlDo+3Zs6eqVKmikSNH6u2339aOHTv0zTff6JtvvnFkWAAAAAAS4deu1Rwdgl0cOhyuQoUKWrJkiX788UeVKFFCw4YN04QJE9SmTRtHhgUAAAAgDXN4v1WjRo3UqFEjR4cBAAAAwEk4tCcIAAAAAJ41h/cEAQAAAEidCg74Q/djDaVzNenEiAaODifR6AkCAAAAYJdYs2H1b2pBEgQAAADAqZAEAQAAAHAqJEEAAAAAnApJEAAAAACnQhIEAAAAwKmQBAEAAABwKiRBAAAAAJwKSRAAAAAAp+Lm6AAAAAAApE5daxXQ7ehYebu7OjqUJCEJAgAAAGCXXnULOzoEuzAcDgAAAIBTIQkCAAAA4FQYDgcAAADALkv2/Ku792Pllc5VzV58wdHhJBpJEAAAAAC79F60T2ZDcjEpVSVBDIcDAAAA4FRIggAAAAA4FZIgAAAAAE6FJAgAAACAUyEJAgAAAOBUSIIAAAAAOBWSIAAAAABOhSQIAAAAgFMhCQIAAADgVNwcHQAAAACA1Glb/1dlNhtycTE5OpQkIQkCAAAAYJfsGT0dHYJdGA4HAAAAwKmQBAEAAABwKgyHAwAAAGCX92bv1K17MfLxdNN37So4OpxEIwkCAAAAYJe1R6/IbEipbF0EhsMBAAAAcC4kQQAAAACcCkkQAAAAAKdCEgQAAADAqZAEAQAAAHAqJEEAAAAAnApJEAAAAACnQhIEAAAAwKnwY6kAAAAA7JLF2113omOV3t3V0aEkCUkQAAAAALvs+qyOo0OwC8PhAAAAADgVhyZBQ4YMkclksroVKVLEkSEBAAAASOMcPhyuePHiWr16teW+m5vDQwIAAACQhjk843Bzc1OOHDkcHQYAAACAJCo/fJVlYYTUND/I4XOCTpw4oVy5cilfvnxq06aNzp8/n2DdqKgoRUREWN0AAAAAOMb129G6Ex2r67ejHR1Kkjg0CapUqZJCQ0P1559/aurUqTpz5oyqV6+uW7duxVs/JCREvr6+lltAQMAzjhgAAABAaufQJKh+/fpq3ry5SpUqpXr16umPP/7QzZs3tXDhwnjr9+/fX+Hh4ZbbhQsXnnHEAAAAAFI7h88JelimTJlUqFAhnTx5Mt7tHh4e8vDweMZRAQAAAEhLHD4n6GGRkZE6deqUcubM6ehQAAAAAKRRDk2C+vTpow0bNujs2bPaunWrmjVrJldXV7Vq1cqRYQEAAABIwxw6HO6ff/5Rq1at9N9//8nPz0/VqlXTX3/9JT8/P0eGBQAAACANc2gSNH/+fEc2DwAAAMAJPVdzggAAAAAgpT1Xq8MBAAAASD1eKeKvW/di5OOZutIKu6I9ffq08uXLl9yxAAAAAEhFvmtXwdEh2MWu4XAFChRQrVq19MMPP+jevXvJHRMAAAAApBi7kqA9e/aoVKlS6tWrl3LkyKFOnTppx44dyR0bAAAAACQ7u5KgMmXKaOLEibp48aJmzpypsLAwVatWTSVKlNC4ceN09erV5I4TAAAAwHPmcsQ9hd28q8sRqWt02FOtDufm5qY33nhDixYt0ujRo3Xy5En16dNHAQEBevfddxUWFpZccQIAAAB4zlQOWaPKo9aqcsgaR4eSJE+VBO3atUsfffSRcubMqXHjxqlPnz46deqUVq1apYsXL6pJkybJFScAAAAAJAu7VocbN26cZs2apWPHjqlBgwaaM2eOGjRoIBeXBzlVUFCQQkNDFRgYmJyxAgAAAMBTsysJmjp1qjp27Kj27dsrZ86c8dbx9/fXjBkznio4AAAAAEhudiVBJ06ceGIdd3d3tWvXzp7DAwAAAECKsWtO0KxZs7Ro0SKb8kWLFmn27NlPHRQAAAAApBS7kqCQkBBly5bNptzf318jR4586qAAAAAAIKXYlQSdP39eQUFBNuV58+bV+fPnnzooAAAAAEgpdiVB/v7+OnDggE35/v37lTVr1qcOCgAAAABSil1JUKtWrdStWzetW7dOsbGxio2N1dq1a9W9e3e1bNkyuWMEAAAAgGRj1+pww4YN09mzZ/Xqq6/Kze3BIcxms959913mBAEAAABOYmzzMrp7P1Ze6VwdHUqS2JUEubu7a8GCBRo2bJj2798vLy8vlSxZUnnz5k3u+AAAAAA8p5q9+IKjQ7CLXUlQnEKFCqlQoULJFQsAAAAApDi7kqDY2FiFhoZqzZo1unLlisxms9X2tWvXJktwAAAAAJDc7EqCunfvrtDQUDVs2FAlSpSQyWRK7rgAAAAAPOfGrTym29Gx8nZ3Va+6hR0dTqLZlQTNnz9fCxcuVIMGDZI7HgAAAACpxOR1J2U2JBeTUlUSZNcS2e7u7ipQoEByxwIAAAAAKc6uJKh3796aOHGiDMNI7ngAAAAAIEXZNRxu8+bNWrdunZYvX67ixYsrXbp0VtsXL16cLMEBAAAAQHKzKwnKlCmTmjVrltyxAAAAAECKsysJmjVrVnLHAQAAAADPhF1zgiQpJiZGq1ev1vTp03Xr1i1J0sWLFxUZGZlswQEAAABAcrOrJ+jcuXN67bXXdP78eUVFRalOnTry8fHR6NGjFRUVpWnTpiV3nAAAAACQLOzqCerevbvKly+vGzduyMvLy1LerFkzrVmzJtmCAwAAAIDkZldP0KZNm7R161a5u7tblQcGBurff/9NlsAAAAAAPN9cXUwyxxpydTE5OpQksSsJMpvNio2NtSn/559/5OPj89RBAQAAAHj+nRjRwNEh2MWu4XB169bVhAkTLPdNJpMiIyM1ePBgNWiQOk8EAAAAAOdgV0/Q2LFjVa9ePRUrVkz37t1T69atdeLECWXLlk0//vhjcscIAAAAAMnGriQod+7c2r9/v+bPn68DBw4oMjJSwcHBatOmjdVCCQAAAADwvLErCZIkNzc3tW3bNjljAQAAAJCKvD55s27di5GPp5t+7VrN0eEkml1J0Jw5cx67/d1337UrGAAAAACpx8F/w2U2pFS2OJx9SVD37t2t7t+/f1937tyRu7u70qdPTxIEAAAA4Lll1+pwN27csLpFRkbq2LFjqlatGgsjAAAAAHiu2ZUExadgwYIaNWqUTS8RAAAAADxPki0Jkh4slnDx4sXkPCQAAAAAJCu75gT9+uuvVvcNw1BYWJgmT56sqlWrJktgAAAAAJAS7EqCmjZtanXfZDLJz89Pr7zyisaOHZsccQEAAABAirArCTKbzckdBwAAAAA8E8k6J+hpjBo1SiaTST169HB0KAAAAADSMLt6gnr16pXouuPGjXtinZ07d2r69OkqVaqUPeEAAAAAcICgbBl0O+q+vD3SOTqUJLErCdq7d6/27t2r+/fvq3DhwpKk48ePy9XVVS+++KKlnsn05J+OjYyMVJs2bfTtt99q+PDh9oQDAAAAwAHW9K7h6BDsYlcS1LhxY/n4+Gj27NnKnDmzpAc/oNqhQwdVr15dvXv3TvSxunTpooYNG6p27dpPTIKioqIUFRVluR8REWFP+AAAAACcmF1zgsaOHauQkBBLAiRJmTNn1vDhw5O0Otz8+fO1Z88ehYSEJKp+SEiIfH19LbeAgIAkxw4AAADAudmVBEVEROjq1as25VevXtWtW7cSdYwLFy6oe/fumjt3rjw9PRO1T//+/RUeHm65XbhwIUlxAwAAAIBdw+GaNWumDh06aOzYsapYsaIkafv27frkk0/0xhtvJOoYu3fv1pUrV6zmEMXGxmrjxo2aPHmyoqKi5OrqarWPh4eHPDw87AkZAAAAQDIrOvBPRcXEysPNVUeGvebocBLNriRo2rRp6tOnj1q3bq379+8/OJCbm4KDgzVmzJhEHePVV1/V33//bVXWoUMHFSlSRP/73/9sEiAAAAAAz5eomFiZjQf/piZ2JUHp06fXlClTNGbMGJ06dUqSlD9/fnl7eyf6GD4+PipRooRVmbe3t7JmzWpTDgAAAADJ5al+LDUsLExhYWEqWLCgvL29ZRhGcsUFAAAAACnCrp6g//77T2+//bbWrVsnk8mkEydOKF++fAoODlbmzJmTtELcw9avX2/XfgAAAACQWHb1BPXs2VPp0qXT+fPnlT59ekt5ixYt9OeffyZbcAAAAACQ3OzqCVq5cqVWrFih3LlzW5UXLFhQ586dS5bAAAAAACAl2NUTdPv2baseoDjXr19nCWsAAAAAzzW7kqDq1atrzpw5lvsmk0lms1lffPGFatWqlWzBAQAAAEBys2s43BdffKFXX31Vu3btUnR0tPr27atDhw7p+vXr2rJlS3LHCAAAAADJxq4kqESJEjp+/LgmT54sHx8fRUZG6o033lCXLl2UM2fO5I4RAAAAwHOoTaW8uh0VI28Pu9IKh0lytPfv39drr72madOmacCAASkREwAAAIBUYFjTEo4OwS5JnhOULl06HThwICViAQAAAIAUZ9fCCG3bttWMGTOSOxYAAAAASHF2Dd6LiYnRzJkztXr1apUrV07e3t5W28eNG5cswQEAAAB4fq0/dkXRMWa5u7moZmF/R4eTaElKgk6fPq3AwEAdPHhQL774oiTp+PHjVnVMJlPyRQcAAADgudUxdKfMhuRikk6HNHR0OImWpCSoYMGCCgsL07p16yRJLVq00FdffaXs2bOnSHAAAAAAkNySNCfIMAyr+8uXL9ft27eTNSAAAAAASEl2LYwQ59GkCAAAAACed0lKgkwmk82cH+YAAQAAAEhNkjQnyDAMtW/fXh4eHpKke/fuqXPnzjarwy1evDj5IgQAAACAZJSkJKhdu3ZW99u2bZuswQAAAABASktSEjRr1qyUigMAAAAAnomnWhgBAAAAAFIbkiAAAAAATiVJw+EAAAAAIM6yj6vpfqxZ6VxTV98KSRAAAAAAuxTL5evoEOySulI2AAAAAHhKJEEAAAAAnArD4QAAAADYpcf8fYqMuq8MHuk0oWUZR4eTaCRBAAAAAOzy6/5/ZTYkF5NSVRLEcDgAAAAAToUkCAAAAIBTIQkCAAAA4FRIggAAAAA4FZIgAAAAAE6FJAgAAACAUyEJAgAAAOBUSIIAAAAAOBV+LBUAAACAXTJ4uOnefbM806WuvhWSIAAAAAB2OTCknqNDsEvqStkAAAAA4CmRBAEAAABwKiRBAAAAAJwKc4IAAAAA2KXa6LWKjIpRBg83bf7fK44OJ9FIggAAAADY5eLNuzIbUsTd+44OJUkYDgcAAADAqZAEAQAAAHAqDk2Cpk6dqlKlSiljxozKmDGjKleurOXLlzsyJAAAAABpnEOToNy5c2vUqFHavXu3du3apVdeeUVNmjTRoUOHHBkWAAAAgDTMoQsjNG7c2Or+iBEjNHXqVP31118qXry4g6ICAAAAkJY9N6vDxcbGatGiRbp9+7YqV64cb52oqChFRUVZ7kdERDyr8AAAAACkEQ5fGOHvv/9WhgwZ5OHhoc6dO2vJkiUqVqxYvHVDQkLk6+truQUEBDzjaAEAAACkdg5PggoXLqx9+/Zp+/bt+vDDD9WuXTsdPnw43rr9+/dXeHi45XbhwoVnHC0AAACA1M7hw+Hc3d1VoEABSVK5cuW0c+dOTZw4UdOnT7ep6+HhIQ8Pj2cdIgAAAIB4VAzKolv3YuTj6fC0Ikmeu2jNZrPVvB8AAAAAz6f5H8Q/l/9559AkqH///qpfv77y5MmjW7duad68eVq/fr1WrFjhyLAAAAAApGEOTYKuXLmid999V2FhYfL19VWpUqW0YsUK1alTx5FhAQAAAEjDHJoEzZgxw5HNAwAAAHBCz92cIAAAAACpQ77+v8tsSC4m6XRIQ0eHk2gOXyIbAAAAAJ4lkiAAAAAAToUkCAAAAIBTIQkCAAAA4FRIggAAAAA4FZIgAAAAAE6FJAgAAACAUyEJAgAAAOBUSIIAAAAAOBU3RwcAAAAAIHUa0KCo7t6PlVc6V0eHkiQkQQAAAADsElw9n6NDsAvD4QAAAAA4FZIgAAAAAE6F4XAAAAAA7DJj02nLnKDUNDSOJAgAAACAXUb8cURmQ3Ixpa75QQyHAwAAAOBUSIIAAAAAOBWSIAAAAABOhSQIAAAAgFMhCQIAAADgVEiCAAAAADgVkiAAAAAAToUkCAAAAIBTIQkCAAAA4FTcHB0AAAAAgNTpdEhDR4dgF3qCAAAAADgVkiAAAAAAToUkCAAAAIBTYU4QAAAAALu0/Gabbt2LkY+nm+Z/UNnR4SQaSRAAAAAAu+w4c11mQ3IxOTqSpGE4HAAAAACnQhIEAAAAwKmQBAEAAABwKiRBAAAAAJwKSRAAAAAAp0ISBAAAAMCpkAQBAAAAcCokQQAAAACcCj+WCgAAAMAuuTJ5KTIqRhk8UldakbqiBQAAAPDc2Py/Vxwdgl0YDgcAAADAqZAEAQAAAHAqJEEAAAAAnIpDk6CQkBBVqFBBPj4+8vf3V9OmTXXs2DFHhgQAAAAgkUoNWaFCA5ar1JAVjg4lSRyaBG3YsEFdunTRX3/9pVWrVun+/fuqW7eubt++7ciwAAAAACRCZFSMomPNioyKcXQoSeLQ1eH+/PNPq/uhoaHy9/fX7t279fLLLzsoKgAAAABp2XO1RHZ4eLgkKUuWLPFuj4qKUlRUlOV+RETEM4kLAAAAQNrx3CyMYDab1aNHD1WtWlUlSpSIt05ISIh8fX0tt4CAgGccJQAAAIDU7rlJgrp06aKDBw9q/vz5Cdbp37+/wsPDLbcLFy48wwgBAAAApAXPxXC4rl27atmyZdq4caNy586dYD0PDw95eHg8w8gAAAAApDUOTYIMw9DHH3+sJUuWaP369QoKCnJkOAAAAACcgEOToC5dumjevHn65Zdf5OPjo0uXLkmSfH195eXl5cjQAAAAAKRRDp0TNHXqVIWHh6tmzZrKmTOn5bZgwQJHhgUAAAAgDXP4cDgAAAAAqdPrpV9QZNR9ZfBI5+hQkuS5WBgBAAAAQOozoWUZR4dgl+dmiWwAAAAAeBZIggAAAAA4FYbDAQAAALDL4Yvhuh9rVjpXFxXL5evocBKNJAgAAACAXRpN2iyzIbmYpNMhDR0dTqIxHA4AAACAUyEJAgAAAOBUSIIAAAAAOBWSIAAAAABOhSQIAAAAgFNhdTgAAIBnaPyq4zZlPesUckAkgPOiJwgAAACAUyEJAgAAAOBUSIIAAAAAOBXmBAEAAACwy8z2FRQdY5a7W+rqWyEJAgAAAGCXmoX9HR2CXVJXygYAAAAAT4kkCAAAAIBTYTgcAAAAALsMXHpQt6Ni5O3hpmFNSzg6nEQjCQIAAABgl7nbz8lsSC4mpaokiOFwAAAAAJwKSRAAAAAAp0ISBAAAAMCpkAQBAAAAcCokQQAAAACcCkkQAAAAAKdCEgQAAADAqZAEAQAAAHAqJEEAAAAA7OLh5ioX04N/UxM3RwcAAAAAIHU6Muw1R4dgF3qCAAAAADgVkiAAAAAAToUkCAAAAIBTYU4QAAAAALu8OnaDbkfdl7dHOq3pXcPR4SQaSRAAAAAAu5y5FimzIbmYohwdSpIwHA4AAACAUyEJAgAAAOBUSIIAAAAAOBWSIAAAAABOhSQIAAAAgFMhCQIAAADgVEiCAAAAADgVkiAAAAAATsWhSdDGjRvVuHFj5cqVSyaTSUuXLnVkOAAAAACSoMQLvgrK5q0SL/g6OpQkcXNk47dv31bp0qXVsWNHvfHGG44MBQAAAEAS/dq1mqNDsItDk6D69eurfv36jgwBAAAAgJNxaBKUVFFRUYqKirLcj4iIcGA0AAAAAFKjVLUwQkhIiHx9fS23gIAAR4cEAAAAIJVJVUlQ//79FR4ebrlduHDB0SEBAAAATqvggD8U2O93FRzwh6NDSZJUNRzOw8NDHh4ejg4DAAAAgKRYs2H1b2qRqnqCAAAAAOBpObQnKDIyUidPnrTcP3PmjPbt26csWbIoT548DowMAAAAQFrl0CRo165dqlWrluV+r169JEnt2rVTaGiog6ICAAAAkJY5NAmqWbOmDCN1jR8EAAAAkLoxJwgAAACAUyEJAgAAAOBUSIIAAAAAOBWSIAAAAABOJVX9WCoAAACA50fXWgV0OzpW3u6ujg4lSUiCAAAAANilV93Cjg7BLgyHAwAAAOBUSIIAAAAAOBWGwwEAAACwy5I9/+ru/Vh5pXNVsxdfcHQ4iUYSBAAAAMAuvRftk9mQXExKVUkQw+EAAAAAOBWSIAAAAABOheFwAFK18auOJ7puzzqFUjASAACQWpAEAUg1kpLwAAAAJIQkCMBzKSUSnviOSe8QAADOhzlBAAAAAJwKSRAAAAAAp8JwOAAOxTwfAADwrJEEAXBqzBMCAMD5kAQBwCMS6p0iOQIAwNq2/q/KbDbk4mJydChJQhIE4Jlh6BsAAGlL9oyejg7BLiRBAJBIDJ0DACBtIAkC8NScuYeHxAgAgNSHJAhAvJw5sQEAAInz3uydunUvRj6ebvquXQVHh5NoJEEAkMxYWAEA4CzWHr0isyGlsnURSIIA4Flh6BwAAM8HkqA0JCnDl+L74pUS+/MFL3Vg6BsAAHAmJEGpQEp8QX3aYyZ2/6dNrJC8SHaeP1w8AADg2SMJeo44+xdUvgwCD/C3AABAyiIJAtIoZ0+qAQAAEkIShOcaV8QTh4Qn7WPFOQAAkg9JkIPwpRUAAABwDJKgZ4CEJ3k5e+8Qryc8zNn/HgAAsAdJEPCcItmBvUiMAADPShZvd92JjlV6d1dHh5IkJEFIE1L7fAkSHqS01P43AgB4Pu36rI6jQ7ALSRDStMQmF8/yiyAJD54n9BoBAJwRSRAgEhPgYSRGAIC0jiQIAPBEJEYAgLSEJAgAYBfmGQEAyg9fZVkYITXNDyIJAgAkq+dxLh4AIGVcvx0tsyHdux/r6FCShCQIAOAQTzsXjyQKAGAvkiAAQKr0LBc0IeECgLSFJAgAgCdgiJ9zSkqizXMPpC4kQQAAJJPncbl9vpwnztM+d8/jcw8gYc9FEvT1119rzJgxunTpkkqXLq1JkyapYsWKjg4LAIBUz9nnXpGcAIiPw5OgBQsWqFevXpo2bZoqVaqkCRMmqF69ejp27Jj8/f0dHR4AAE6NJAJAWuTi6ADGjRun999/Xx06dFCxYsU0bdo0pU+fXjNnznR0aAAAAADSIIf2BEVHR2v37t3q37+/pczFxUW1a9fWtm3bbOpHRUUpKirKcj88PFySFBERkfLBJsK925GODgEAAKRCz8t3GSCpzFF3ZDYkmRz/Oo5r3zCMJ9Z1aBJ07do1xcbGKnv27Fbl2bNn19GjR23qh4SEaOjQoTblAQEBKRYjAABASvvU0QEAycB3vKMjeODWrVvy9fV9bB2HzwlKiv79+6tXr16W+2azWdevX1fWrFllMpkcGNmDzDMgIEAXLlxQxowZHRpLWsT5TXmc45TF+U1ZnN+UxflNWZzflMX5TVnP0/k1DEO3bt1Srly5nljXoUlQtmzZ5OrqqsuXL1uVX758WTly5LCp7+HhIQ8PD6uyTJkypWSISZYxY0aHvwDSMs5vyuMcpyzOb8ri/KYszm/K4vymLM5vynpezu+TeoDiOHRhBHd3d5UrV05r1qyxlJnNZq1Zs0aVK1d2YGQAAAAA0iqHD4fr1auX2rVrp/Lly6tixYqaMGGCbt++rQ4dOjg6NAAAAABpkMOToBYtWujq1asaNGiQLl26pDJlyujPP/+0WSzheefh4aHBgwfbDNdD8uD8pjzOccri/KYszm/K4vymLM5vyuL8pqzUen5NRmLWkAMAAACANMLhP5YKAAAAAM8SSRAAAAAAp0ISBAAAAMCpkAQBAAAAcCokQcnk66+/VmBgoDw9PVWpUiXt2LHD0SGlGRs3blTjxo2VK1cumUwmLV261NEhpRkhISGqUKGCfHx85O/vr6ZNm+rYsWOODivNmDp1qkqVKmX5AbnKlStr+fLljg4rzRo1apRMJpN69Ojh6FDShCFDhshkMlndihQp4uiw0pR///1Xbdu2VdasWeXl5aWSJUtq165djg4rzQgMDLR5DZtMJnXp0sXRoaV6sbGxGjhwoIKCguTl5aX8+fNr2LBhSk3rrZEEJYMFCxaoV69eGjx4sPbs2aPSpUurXr16unLliqNDSxNu376t0qVL6+uvv3Z0KGnOhg0b1KVLF/31119atWqV7t+/r7p16+r27duODi1NyJ07t0aNGqXdu3dr165deuWVV9SkSRMdOnTI0aGlOTt37tT06dNVqlQpR4eSphQvXlxhYWGW2+bNmx0dUppx48YNVa1aVenSpdPy5ct1+PBhjR07VpkzZ3Z0aGnGzp07rV6/q1atkiQ1b97cwZGlfqNHj9bUqVM1efJkHTlyRKNHj9YXX3yhSZMmOTq0RGOJ7GRQqVIlVahQQZMnT5Ykmc1mBQQE6OOPP1a/fv0cHF3aYjKZtGTJEjVt2tTRoaRJV69elb+/vzZs2KCXX37Z0eGkSVmyZNGYMWMUHBzs6FDSjMjISL344ouaMmWKhg8frjJlymjChAmODivVGzJkiJYuXap9+/Y5OpQ0qV+/ftqyZYs2bdrk6FCcRo8ePbRs2TKdOHFCJpPJ0eGkao0aNVL27Nk1Y8YMS9mbb74pLy8v/fDDDw6MLPHoCXpK0dHR2r17t2rXrm0pc3FxUe3atbVt2zYHRgYkXXh4uKQHX9SRvGJjYzV//nzdvn1blStXdnQ4aUqXLl3UsGFDq/dhJI8TJ04oV65cypcvn9q0aaPz5887OqQ049dff1X58uXVvHlz+fv7q2zZsvr2228dHVaaFR0drR9++EEdO3YkAUoGVapU0Zo1a3T8+HFJ0v79+7V582bVr1/fwZElnpujA0jtrl27ptjYWGXPnt2qPHv27Dp69KiDogKSzmw2q0ePHqpatapKlCjh6HDSjL///luVK1fWvXv3lCFDBi1ZskTFihVzdFhpxvz587Vnzx7t3LnT0aGkOZUqVVJoaKgKFy6ssLAwDR06VNWrV9fBgwfl4+Pj6PBSvdOnT2vq1Knq1auXPv30U+3cuVPdunWTu7u72rVr5+jw0pylS5fq5s2bat++vaNDSRP69euniIgIFSlSRK6uroqNjdWIESPUpk0bR4eWaCRBACQ9uJp+8OBBxvwns8KFC2vfvn0KDw/XTz/9pHbt2mnDhg0kQsngwoUL6t69u1atWiVPT09Hh5PmPHxFt1SpUqpUqZLy5s2rhQsXMpwzGZjNZpUvX14jR46UJJUtW1YHDx7UtGnTSIJSwIwZM1S/fn3lypXL0aGkCQsXLtTcuXM1b948FS9eXPv27VOPHj2UK1euVPP6JQl6StmyZZOrq6suX75sVX758mXlyJHDQVEBSdO1a1ctW7ZMGzduVO7cuR0dTpri7u6uAgUKSJLKlSunnTt3auLEiZo+fbqDI0v9du/erStXrujFF1+0lMXGxmrjxo2aPHmyoqKi5Orq6sAI05ZMmTKpUKFCOnnypKNDSRNy5sxpczGkaNGi+vnnnx0UUdp17tw5rV69WosXL3Z0KGnGJ598on79+qlly5aSpJIlS+rcuXMKCQlJNUkQc4Kekru7u8qVK6c1a9ZYysxms9asWcO4fzz3DMNQ165dtWTJEq1du1ZBQUGODinNM5vNioqKcnQYacKrr76qv//+W/v27bPcypcvrzZt2mjfvn0kQMksMjJSp06dUs6cOR0dSppQtWpVm58kOH78uPLmzeugiNKuWbNmyd/fXw0bNnR0KGnGnTt35OJinUa4urrKbDY7KKKkoycoGfTq1Uvt2rVT+fLlVbFiRU2YMEG3b99Whw4dHB1amhAZGWl15fHMmTPat2+fsmTJojx58jgwstSvS5cumjdvnn755Rf5+Pjo0qVLkiRfX195eXk5OLrUr3///qpfv77y5MmjW7duad68eVq/fr1WrFjh6NDSBB8fH5v5a97e3sqaNSvz2pJBnz591LhxY+XNm1cXL17U4MGD5erqqlatWjk6tDShZ8+eqlKlikaOHKm3335bO3bs0DfffKNvvvnG0aGlKWazWbNmzVK7du3k5sbX3uTSuHFjjRgxQnny5FHx4sW1d+9ejRs3Th07dnR0aIlnIFlMmjTJyJMnj+Hu7m5UrFjR+OuvvxwdUpqxbt06Q5LNrV27do4OLdWL77xKMmbNmuXo0NKEjh07Gnnz5jXc3d0NPz8/49VXXzVWrlzp6LDStBo1ahjdu3d3dBhpQosWLYycOXMa7u7uxgsvvGC0aNHCOHnypKPDSlN+++03o0SJEoaHh4dRpEgR45tvvnF0SGnOihUrDEnGsWPHHB1KmhIREWF0797dyJMnj+Hp6Wnky5fPGDBggBEVFeXo0BKN3wkCAAAA4FSYEwQAAADAqZAEAQAAAHAqJEEAAAAAnApJEAAAAACnQhIEAAAAwKmQBAEAAABwKiRBAAAAAJwKSRAAAAAAp0ISBAB4aqGhocqUKVOKt3P27FmZTCbt27cvxdt6Wu3bt1fTpk0dHQYAIB4kQQDghLZt2yZXV1c1bNgwyfsGBgZqwoQJVmUtWrTQ8ePHkym6B+JLIgICAhQWFqYSJUoka1sP+/jjj1W0aNF4t50/f16urq769ddfU6x9AEDKIwkCACc0Y8YMffzxx9q4caMuXrz41Mfz8vKSv79/MkT2eK6ursqRI4fc3NxSrI3g4GAdPXpUW7dutdkWGhoqf39/NWjQIMXaBwCkPJIgAHAykZGRWrBggT788EM1bNhQoaGhNnV+++03VahQQZ6ensqWLZuaNWsmSapZs6bOnTunnj17ymQyyWQySbIeDnf8+HGZTCYdPXrU6pjjx49X/vz5JUmxsbEKDg5WUFCQvLy8VLhwYU2cONFSd8iQIZo9e7Z++eUXSzvr16+Pdzjchg0bVLFiRXl4eChnzpzq16+fYmJiLNtr1qypbt26qW/fvsqSJYty5MihIUOGJHh+ypQpoxdffFEzZ860KjcMQ6GhoWrXrp1MJtNj449PfD1oZcqUsYrl5s2beu+99+Tn56eMGTPqlVde0f79+x97XABA0pEEAYCTWbhwoYoUKaLChQurbdu2mjlzpgzDsGz//fff1axZMzVo0EB79+7VmjVrVLFiRUnS4sWLlTt3bn3++ecKCwtTWFiYzfELFSqk8uXLa+7cuVblc+fOVevWrSVJZrNZuXPn1qJFi3T48GENGjRIn376qRYuXChJ6tOnj95++2299tprlnaqVKli09a///6rBg0aqEKFCtq/f7+mTp2qGTNmaPjw4Vb1Zs+eLW9vb23fvl1ffPGFPv/8c61atSrBcxQcHKyFCxfq9u3blrL169frzJkz6tix4xPjt1fz5s115coVLV++XLt379aLL76oV199VdevX3+q4wIAHmEAAJxKlSpVjAkTJhiGYRj37983smXLZqxbt86yvXLlykabNm0S3D9v3rzG+PHjrcpmzZpl+Pr6Wu6PHz/eyJ8/v+X+sWPHDEnGkSNHEjxuly5djDfffNNyv127dkaTJk2s6pw5c8aQZOzdu9cwDMP49NNPjcKFCxtms9lS5+uvvzYyZMhgxMbGGoZhGDVq1DCqVatmdZwKFSoY//vf/xKM5caNG4anp6cxa9YsS9k777xjc5ykxB/feStdurQxePBgwzAMY9OmTUbGjBmNe/fuWdXJnz+/MX369ATbBQAkHT1BAOBEjh07ph07dqhVq1aSJDc3N7Vo0UIzZsyw1Nm3b59effXVp2qnZcuWOnv2rP766y9JD3qBXnzxRRUpUsRS5+uvv1a5cuXk5+enDBky6JtvvtH58+eT1M6RI0dUuXJly7A8SapataoiIyP1zz//WMpKlSpltV/OnDl15cqVBI+bKVMmvfHGG5YhcREREfr5558VHBycrPE/bP/+/YqMjFTWrFmVIUMGy+3MmTM6deqU3ccFANhKuZmlAIDnzowZMxQTE6NcuXJZygzDkIeHhyZPnixfX195eXk9dTs5cuTQK6+8onnz5umll17SvHnz9OGHH1q2z58/X3369NHYsWNVuXJl+fj4aMyYMdq+fftTtx2fdOnSWd03mUwym82P3Sc4OFivvvqqTp48qXXr1snV1VXNmze3O34XFxerYYeSdP/+fcv/IyMjlTNnTq1fv95m32ex/DgAOBOSIABwEjExMZozZ47Gjh2runXrWm1r2rSpfvzxR3Xu3FmlSpXSmjVr1KFDh3iP4+7urtjY2Ce216ZNG/Xt21etWrXS6dOn1bJlS8u2LVu2qEqVKvroo48sZY/2diSmnaJFi+rnn3+WYRiW3qAtW7bIx8dHuXPnfmKMj1OrVi0FBQVp1qxZWrdunVq2bClvb+9Ex/8oPz8/qzlUEREROnPmjOX+iy++qEuXLsnNzU2BgYFPFTsA4PEYDgcATmLZsmW6ceOGgoODVaJECavbm2++aRkSN3jwYP34448aPHiwjhw5or///lujR4+2HCcwMFAbN27Uv//+q2vXriXY3htvvKFbt27pww8/VK1atax6nwoWLKhdu3ZpxYoVOn78uAYOHKidO3da7R8YGKgDBw7o2LFjunbtmlWvSZyPPvpIFy5c0Mcff6yjR4/ql19+0eDBg9WrVy+5uDzdR5zJZFLHjh01depUbdu2zWooXGLif9Qrr7yi77//Xps2bdLff/+tdu3aydXV1bK9du3aqly5spo2baqVK1fq7Nmz2rp1qwYMGKBdu3Y91WMBAFgjCQIAJzFjxgzVrl1bvr6+NtvefPNN7dq1SwcOHFDNmjW1aNEi/frrrypTpoxeeeUV7dixw1L3888/19mzZ5U/f375+fkl2J6Pj48aN26s/fv3q02bNlbbOnXqpDfeeEMtWrRQpUqV9N9//1n1qkjS+++/r8KFC6t8+fLy8/PTli1bbNp44YUX9Mcff2jHjh0qXbq0OnfurODgYH322WdJPT3xat++vcLDw1W8eHFVqlQpSfE/qn///qpRo4YaNWqkhg0bqmnTppYlw6UHSdcff/yhl19+WR06dFChQoXUsmVLnTt3TtmzZ0+WxwMAeMBkPDpAGQD+X3t2QAMAAIAgrH9re8jfggEAcMwJAgAAUkQQAACQIoIAAIAUEQQAAKSIIAAAIEUEAQAAKSIIAABIEUEAAECKCAIAAFJEEAAAkCKCAACAlAGd9q23/SDfIQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(all_activations_relu, bins=100, alpha=0.5, label='Original')\n",
    "for method, threshold in optimal_thresholds_relu.items():\n",
    "    plt.axvline(threshold, linestyle='--', linewidth=2, label=f'{method}: {threshold:.2f}')\n",
    "\n",
    "plt.title('Activation Distribution with Optimal Quantization Thresholds First Relu Layer')\n",
    "plt.xlabel('Activation Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "Df7eKzh4oj5X",
   "metadata": {
    "id": "Df7eKzh4oj5X"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(all_activations_project, bins=100, alpha=0.5, label='Original')\n",
    "for method, threshold in optimal_thresholds_project.items():\n",
    "    plt.axvline(threshold, linestyle='--', linewidth=2, label=f'{method}: {threshold:.2f}')\n",
    "\n",
    "plt.title('Activation Distribution with Optimal Quantization Thresholds Project BN layer')\n",
    "plt.xlabel('Activation Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c967d41-439d-405b-815f-be641f1768fe",
   "metadata": {
    "id": "4c967d41-439d-405b-815f-be641f1768fe"
   },
   "source": [
    "## Model Evaluation\n",
    "Finally, we can demonstrate the impact of these different thresholds on the model's overall accuracy.\n",
    "In order to evaluate our models, we first need to load the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9199b59c4f10eca1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#val_dataset = get_dataset(batch_size=50, shuffle=False)\n",
    "#val_dataset = ImageNet(root='./imagenet', split='val', transform=weights.transforms())\n",
    "#val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "631780a79e2cedf0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [07:28<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -5.2923, Accuracy: 33872/50000 (68%)\n",
      "\n",
      "Float model's Top 1 accuracy on the Imagenet validation set: 67.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "val_dataset = ImageNet(root='./imagenet', split='val', transform=weights.transforms())\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            #print(\"test_loss\", test_loss)\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy * 100.0))\n",
    "    \n",
    "    return test_loss, accuracy \n",
    "\n",
    "_, float_accuracy = evaluate(float_model, val_loader)\n",
    "print(f\"Float model's Top 1 accuracy on the Imagenet validation set: {(float_accuracy * 100.0):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07a22d28-56ff-46de-8ed0-1163c3b7a613",
   "metadata": {
    "id": "07a22d28-56ff-46de-8ed0-1163c3b7a613"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [04:18<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -6.0600, Accuracy: 35920/50000 (72%)\n",
      "\n",
      "Results for QuantizationErrorMethod.MSE: Loss = -6.05997125, Accuracy = 0.7184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [05:56<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -6.2230, Accuracy: 35963/50000 (72%)\n",
      "\n",
      "Results for QuantizationErrorMethod.NOCLIPPING: Loss = -6.2229875, Accuracy = 0.71926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = {}\n",
    "\n",
    "for error_method, data in quantized_models_dict.items():\n",
    "    quantized_model = data[\"quantized_model\"]\n",
    "\n",
    "    results = evaluate(quantized_model, val_loader)\n",
    "\n",
    "    evaluation_results[error_method] = results\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Results for {error_method}: Loss = {results[0]}, Accuracy = {results[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GpEZ2E1qzWl3",
   "metadata": {
    "id": "GpEZ2E1qzWl3"
   },
   "source": [
    "These results are consistent across many models, which is why MSE is set as the default method.\n",
    "\n",
    "Each of MCT's error methods impacts models differently, so it is recommended to include this metric as part of hyperparameter tuning when optimizing quantized model accuracy.\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "In this tutorial, we explored the process of finding optimal activation thresholds using different error metrics in MCT’s post-training quantization workflow. By comparing the **MSE** and **No Clipping** methods, we demonstrated how the choice of threshold can significantly affect the activation distributions and, ultimately, the quantized model’s performance. While **MSE** is commonly the best choice and is used by default, it is essential to consider other error metrics during hyperparameter tuning to achieve the best results for different models.\n",
    "\n",
    "Understanding the impact of these thresholds on data loss and resolution is critical when fine-tuning the quantization process for deployment, making this a valuable step in building high-performance quantized models.\n",
    "\n",
    "\n",
    "## Appendix\n",
    "Below is a code snippet that can be used to extract information from each layer in the MCT quantization output, assisting in analyzing the layer-wise quantization details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "qml4LLmWZLP4",
   "metadata": {
    "id": "qml4LLmWZLP4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in /mnt/share2/work/sss/ve310_1_pt/lib/python3.10/site-packages (1.8.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "odict_keys(['features_0_0_bn.weight', 'features_0_0_bn.layer.bias', 'features_1_conv_0_0_bn.weight', 'features_1_conv_0_0_bn.layer.bias', 'features_1_conv_1_bn.weight', 'features_1_conv_1_bn.layer.bias', 'features_2_conv_0_0_bn.weight', 'features_2_conv_0_0_bn.layer.bias', 'features_2_conv_1_0_bn.weight', 'features_2_conv_1_0_bn.layer.bias', 'features_2_conv_2_bn.weight', 'features_2_conv_2_bn.layer.bias', 'features_3_conv_0_0_bn.weight', 'features_3_conv_0_0_bn.layer.bias', 'features_3_conv_1_0_bn.weight', 'features_3_conv_1_0_bn.layer.bias', 'features_3_conv_2_bn.weight', 'features_3_conv_2_bn.layer.bias', 'features_4_conv_0_0_bn.weight', 'features_4_conv_0_0_bn.layer.bias', 'features_4_conv_1_0_bn.weight', 'features_4_conv_1_0_bn.layer.bias', 'features_4_conv_2_bn.weight', 'features_4_conv_2_bn.layer.bias', 'features_5_conv_0_0_bn.weight', 'features_5_conv_0_0_bn.layer.bias', 'features_5_conv_1_0_bn.weight', 'features_5_conv_1_0_bn.layer.bias', 'features_5_conv_2_bn.weight', 'features_5_conv_2_bn.layer.bias', 'features_6_conv_0_0_bn.weight', 'features_6_conv_0_0_bn.layer.bias', 'features_6_conv_1_0_bn.weight', 'features_6_conv_1_0_bn.layer.bias', 'features_6_conv_2_bn.weight', 'features_6_conv_2_bn.layer.bias', 'features_7_conv_0_0_bn.weight', 'features_7_conv_0_0_bn.layer.bias', 'features_7_conv_1_0_bn.weight', 'features_7_conv_1_0_bn.layer.bias', 'features_7_conv_2_bn.weight', 'features_7_conv_2_bn.layer.bias', 'features_8_conv_0_0_bn.weight', 'features_8_conv_0_0_bn.layer.bias', 'features_8_conv_1_0_bn.weight', 'features_8_conv_1_0_bn.layer.bias', 'features_8_conv_2_bn.weight', 'features_8_conv_2_bn.layer.bias', 'features_9_conv_0_0_bn.weight', 'features_9_conv_0_0_bn.layer.bias', 'features_9_conv_1_0_bn.weight', 'features_9_conv_1_0_bn.layer.bias', 'features_9_conv_2_bn.weight', 'features_9_conv_2_bn.layer.bias', 'features_10_conv_0_0_bn.weight', 'features_10_conv_0_0_bn.layer.bias', 'features_10_conv_1_0_bn.weight', 'features_10_conv_1_0_bn.layer.bias', 'features_10_conv_2_bn.weight', 'features_10_conv_2_bn.layer.bias', 'features_11_conv_0_0_bn.weight', 'features_11_conv_0_0_bn.layer.bias', 'features_11_conv_1_0_bn.weight', 'features_11_conv_1_0_bn.layer.bias', 'features_11_conv_2_bn.weight', 'features_11_conv_2_bn.layer.bias', 'features_12_conv_0_0_bn.weight', 'features_12_conv_0_0_bn.layer.bias', 'features_12_conv_1_0_bn.weight', 'features_12_conv_1_0_bn.layer.bias', 'features_12_conv_2_bn.weight', 'features_12_conv_2_bn.layer.bias', 'features_13_conv_0_0_bn.weight', 'features_13_conv_0_0_bn.layer.bias', 'features_13_conv_1_0_bn.weight', 'features_13_conv_1_0_bn.layer.bias', 'features_13_conv_2_bn.weight', 'features_13_conv_2_bn.layer.bias', 'features_14_conv_0_0_bn.weight', 'features_14_conv_0_0_bn.layer.bias', 'features_14_conv_1_0_bn.weight', 'features_14_conv_1_0_bn.layer.bias', 'features_14_conv_2_bn.weight', 'features_14_conv_2_bn.layer.bias', 'features_15_conv_0_0_bn.weight', 'features_15_conv_0_0_bn.layer.bias', 'features_15_conv_1_0_bn.weight', 'features_15_conv_1_0_bn.layer.bias', 'features_15_conv_2_bn.weight', 'features_15_conv_2_bn.layer.bias', 'features_16_conv_0_0_bn.weight', 'features_16_conv_0_0_bn.layer.bias', 'features_16_conv_1_0_bn.weight', 'features_16_conv_1_0_bn.layer.bias', 'features_16_conv_2_bn.weight', 'features_16_conv_2_bn.layer.bias', 'features_17_conv_0_0_bn.weight', 'features_17_conv_0_0_bn.layer.bias', 'features_17_conv_1_0_bn.weight', 'features_17_conv_1_0_bn.layer.bias', 'features_17_conv_2_bn.weight', 'features_17_conv_2_bn.layer.bias', 'features_18_0_bn.weight', 'features_18_0_bn.layer.bias', 'classifier_1.weight', 'classifier_1.layer.bias'])\n",
      "====================================================================================================\n",
      "Layer (type:depth-idx)                             Output Shape              Param #\n",
      "====================================================================================================\n",
      "PytorchModel                                       [1, 1000]                 --\n",
      "├─DummyPlaceHolder: 1-1                            [1, 3, 224, 224]          --\n",
      "├─PytorchActivationQuantizationHolder: 1-2         [1, 3, 224, 224]          --\n",
      "├─PytorchQuantizationWrapper: 1-3                  [1, 32, 112, 112]         864\n",
      "│    └─Conv2d: 2-1                                 [1, 32, 112, 112]         32\n",
      "├─ReLU6: 1-4                                       [1, 32, 112, 112]         --\n",
      "├─PytorchActivationQuantizationHolder: 1-5         [1, 32, 112, 112]         --\n",
      "├─PytorchQuantizationWrapper: 1-6                  [1, 32, 112, 112]         288\n",
      "│    └─Conv2d: 2-2                                 [1, 32, 112, 112]         32\n",
      "├─ReLU6: 1-7                                       [1, 32, 112, 112]         --\n",
      "├─PytorchActivationQuantizationHolder: 1-8         [1, 32, 112, 112]         --\n",
      "├─PytorchQuantizationWrapper: 1-9                  [1, 16, 112, 112]         512\n",
      "│    └─Conv2d: 2-3                                 [1, 16, 112, 112]         16\n",
      "├─PytorchActivationQuantizationHolder: 1-10        [1, 16, 112, 112]         --\n",
      "├─PytorchQuantizationWrapper: 1-11                 [1, 96, 112, 112]         1,536\n",
      "│    └─Conv2d: 2-4                                 [1, 96, 112, 112]         96\n",
      "├─ReLU6: 1-12                                      [1, 96, 112, 112]         --\n",
      "├─PytorchActivationQuantizationHolder: 1-13        [1, 96, 112, 112]         --\n",
      "├─PytorchQuantizationWrapper: 1-14                 [1, 96, 56, 56]           864\n",
      "│    └─Conv2d: 2-5                                 [1, 96, 56, 56]           96\n",
      "├─ReLU6: 1-15                                      [1, 96, 56, 56]           --\n",
      "├─PytorchActivationQuantizationHolder: 1-16        [1, 96, 56, 56]           --\n",
      "├─PytorchQuantizationWrapper: 1-17                 [1, 24, 56, 56]           2,304\n",
      "│    └─Conv2d: 2-6                                 [1, 24, 56, 56]           24\n",
      "├─PytorchActivationQuantizationHolder: 1-18        [1, 24, 56, 56]           --\n",
      "├─PytorchQuantizationWrapper: 1-19                 [1, 144, 56, 56]          3,456\n",
      "│    └─Conv2d: 2-7                                 [1, 144, 56, 56]          144\n",
      "├─ReLU6: 1-20                                      [1, 144, 56, 56]          --\n",
      "├─PytorchActivationQuantizationHolder: 1-21        [1, 144, 56, 56]          --\n",
      "├─PytorchQuantizationWrapper: 1-22                 [1, 144, 56, 56]          1,296\n",
      "│    └─Conv2d: 2-8                                 [1, 144, 56, 56]          144\n",
      "├─ReLU6: 1-23                                      [1, 144, 56, 56]          --\n",
      "├─PytorchActivationQuantizationHolder: 1-24        [1, 144, 56, 56]          --\n",
      "├─PytorchQuantizationWrapper: 1-25                 [1, 24, 56, 56]           3,456\n",
      "│    └─Conv2d: 2-9                                 [1, 24, 56, 56]           24\n",
      "├─PytorchActivationQuantizationHolder: 1-26        [1, 24, 56, 56]           --\n",
      "├─PytorchActivationQuantizationHolder: 1-27        [1, 24, 56, 56]           --\n",
      "├─PytorchQuantizationWrapper: 1-28                 [1, 144, 56, 56]          3,456\n",
      "│    └─Conv2d: 2-10                                [1, 144, 56, 56]          144\n",
      "├─ReLU6: 1-29                                      [1, 144, 56, 56]          --\n",
      "├─PytorchActivationQuantizationHolder: 1-30        [1, 144, 56, 56]          --\n",
      "├─PytorchQuantizationWrapper: 1-31                 [1, 144, 28, 28]          1,296\n",
      "│    └─Conv2d: 2-11                                [1, 144, 28, 28]          144\n",
      "├─ReLU6: 1-32                                      [1, 144, 28, 28]          --\n",
      "├─PytorchActivationQuantizationHolder: 1-33        [1, 144, 28, 28]          --\n",
      "├─PytorchQuantizationWrapper: 1-34                 [1, 32, 28, 28]           4,608\n",
      "│    └─Conv2d: 2-12                                [1, 32, 28, 28]           32\n",
      "├─PytorchActivationQuantizationHolder: 1-35        [1, 32, 28, 28]           --\n",
      "├─PytorchQuantizationWrapper: 1-36                 [1, 192, 28, 28]          6,144\n",
      "│    └─Conv2d: 2-13                                [1, 192, 28, 28]          192\n",
      "├─ReLU6: 1-37                                      [1, 192, 28, 28]          --\n",
      "├─PytorchActivationQuantizationHolder: 1-38        [1, 192, 28, 28]          --\n",
      "├─PytorchQuantizationWrapper: 1-39                 [1, 192, 28, 28]          1,728\n",
      "│    └─Conv2d: 2-14                                [1, 192, 28, 28]          192\n",
      "├─ReLU6: 1-40                                      [1, 192, 28, 28]          --\n",
      "├─PytorchActivationQuantizationHolder: 1-41        [1, 192, 28, 28]          --\n",
      "├─PytorchQuantizationWrapper: 1-42                 [1, 32, 28, 28]           6,144\n",
      "│    └─Conv2d: 2-15                                [1, 32, 28, 28]           32\n",
      "├─PytorchActivationQuantizationHolder: 1-43        [1, 32, 28, 28]           --\n",
      "├─PytorchActivationQuantizationHolder: 1-44        [1, 32, 28, 28]           --\n",
      "├─PytorchQuantizationWrapper: 1-45                 [1, 192, 28, 28]          6,144\n",
      "│    └─Conv2d: 2-16                                [1, 192, 28, 28]          192\n",
      "├─ReLU6: 1-46                                      [1, 192, 28, 28]          --\n",
      "├─PytorchActivationQuantizationHolder: 1-47        [1, 192, 28, 28]          --\n",
      "├─PytorchQuantizationWrapper: 1-48                 [1, 192, 28, 28]          1,728\n",
      "│    └─Conv2d: 2-17                                [1, 192, 28, 28]          192\n",
      "├─ReLU6: 1-49                                      [1, 192, 28, 28]          --\n",
      "├─PytorchActivationQuantizationHolder: 1-50        [1, 192, 28, 28]          --\n",
      "├─PytorchQuantizationWrapper: 1-51                 [1, 32, 28, 28]           6,144\n",
      "│    └─Conv2d: 2-18                                [1, 32, 28, 28]           32\n",
      "├─PytorchActivationQuantizationHolder: 1-52        [1, 32, 28, 28]           --\n",
      "├─PytorchActivationQuantizationHolder: 1-53        [1, 32, 28, 28]           --\n",
      "├─PytorchQuantizationWrapper: 1-54                 [1, 192, 28, 28]          6,144\n",
      "│    └─Conv2d: 2-19                                [1, 192, 28, 28]          192\n",
      "├─ReLU6: 1-55                                      [1, 192, 28, 28]          --\n",
      "├─PytorchActivationQuantizationHolder: 1-56        [1, 192, 28, 28]          --\n",
      "├─PytorchQuantizationWrapper: 1-57                 [1, 192, 14, 14]          1,728\n",
      "│    └─Conv2d: 2-20                                [1, 192, 14, 14]          192\n",
      "├─ReLU6: 1-58                                      [1, 192, 14, 14]          --\n",
      "├─PytorchActivationQuantizationHolder: 1-59        [1, 192, 14, 14]          --\n",
      "├─PytorchQuantizationWrapper: 1-60                 [1, 64, 14, 14]           12,288\n",
      "│    └─Conv2d: 2-21                                [1, 64, 14, 14]           64\n",
      "├─PytorchActivationQuantizationHolder: 1-61        [1, 64, 14, 14]           --\n",
      "├─PytorchQuantizationWrapper: 1-62                 [1, 384, 14, 14]          24,576\n",
      "│    └─Conv2d: 2-22                                [1, 384, 14, 14]          384\n",
      "├─ReLU6: 1-63                                      [1, 384, 14, 14]          --\n",
      "├─PytorchActivationQuantizationHolder: 1-64        [1, 384, 14, 14]          --\n",
      "├─PytorchQuantizationWrapper: 1-65                 [1, 384, 14, 14]          3,456\n",
      "│    └─Conv2d: 2-23                                [1, 384, 14, 14]          384\n",
      "├─ReLU6: 1-66                                      [1, 384, 14, 14]          --\n",
      "├─PytorchActivationQuantizationHolder: 1-67        [1, 384, 14, 14]          --\n",
      "├─PytorchQuantizationWrapper: 1-68                 [1, 64, 14, 14]           24,576\n",
      "│    └─Conv2d: 2-24                                [1, 64, 14, 14]           64\n",
      "├─PytorchActivationQuantizationHolder: 1-69        [1, 64, 14, 14]           --\n",
      "├─PytorchActivationQuantizationHolder: 1-70        [1, 64, 14, 14]           --\n",
      "├─PytorchQuantizationWrapper: 1-71                 [1, 384, 14, 14]          24,576\n",
      "│    └─Conv2d: 2-25                                [1, 384, 14, 14]          384\n",
      "├─ReLU6: 1-72                                      [1, 384, 14, 14]          --\n",
      "├─PytorchActivationQuantizationHolder: 1-73        [1, 384, 14, 14]          --\n",
      "├─PytorchQuantizationWrapper: 1-74                 [1, 384, 14, 14]          3,456\n",
      "│    └─Conv2d: 2-26                                [1, 384, 14, 14]          384\n",
      "├─ReLU6: 1-75                                      [1, 384, 14, 14]          --\n",
      "├─PytorchActivationQuantizationHolder: 1-76        [1, 384, 14, 14]          --\n",
      "├─PytorchQuantizationWrapper: 1-77                 [1, 64, 14, 14]           24,576\n",
      "│    └─Conv2d: 2-27                                [1, 64, 14, 14]           64\n",
      "├─PytorchActivationQuantizationHolder: 1-78        [1, 64, 14, 14]           --\n",
      "├─PytorchActivationQuantizationHolder: 1-79        [1, 64, 14, 14]           --\n",
      "├─PytorchQuantizationWrapper: 1-80                 [1, 384, 14, 14]          24,576\n",
      "│    └─Conv2d: 2-28                                [1, 384, 14, 14]          384\n",
      "├─ReLU6: 1-81                                      [1, 384, 14, 14]          --\n",
      "├─PytorchActivationQuantizationHolder: 1-82        [1, 384, 14, 14]          --\n",
      "├─PytorchQuantizationWrapper: 1-83                 [1, 384, 14, 14]          3,456\n",
      "│    └─Conv2d: 2-29                                [1, 384, 14, 14]          384\n",
      "├─ReLU6: 1-84                                      [1, 384, 14, 14]          --\n",
      "├─PytorchActivationQuantizationHolder: 1-85        [1, 384, 14, 14]          --\n",
      "├─PytorchQuantizationWrapper: 1-86                 [1, 64, 14, 14]           24,576\n",
      "│    └─Conv2d: 2-30                                [1, 64, 14, 14]           64\n",
      "├─PytorchActivationQuantizationHolder: 1-87        [1, 64, 14, 14]           --\n",
      "├─PytorchActivationQuantizationHolder: 1-88        [1, 64, 14, 14]           --\n",
      "├─PytorchQuantizationWrapper: 1-89                 [1, 384, 14, 14]          24,576\n",
      "│    └─Conv2d: 2-31                                [1, 384, 14, 14]          384\n",
      "├─ReLU6: 1-90                                      [1, 384, 14, 14]          --\n",
      "├─PytorchActivationQuantizationHolder: 1-91        [1, 384, 14, 14]          --\n",
      "├─PytorchQuantizationWrapper: 1-92                 [1, 384, 14, 14]          3,456\n",
      "│    └─Conv2d: 2-32                                [1, 384, 14, 14]          384\n",
      "├─ReLU6: 1-93                                      [1, 384, 14, 14]          --\n",
      "├─PytorchActivationQuantizationHolder: 1-94        [1, 384, 14, 14]          --\n",
      "├─PytorchQuantizationWrapper: 1-95                 [1, 96, 14, 14]           36,864\n",
      "│    └─Conv2d: 2-33                                [1, 96, 14, 14]           96\n",
      "├─PytorchActivationQuantizationHolder: 1-96        [1, 96, 14, 14]           --\n",
      "├─PytorchQuantizationWrapper: 1-97                 [1, 576, 14, 14]          55,296\n",
      "│    └─Conv2d: 2-34                                [1, 576, 14, 14]          576\n",
      "├─ReLU6: 1-98                                      [1, 576, 14, 14]          --\n",
      "├─PytorchActivationQuantizationHolder: 1-99        [1, 576, 14, 14]          --\n",
      "├─PytorchQuantizationWrapper: 1-100                [1, 576, 14, 14]          5,184\n",
      "│    └─Conv2d: 2-35                                [1, 576, 14, 14]          576\n",
      "├─ReLU6: 1-101                                     [1, 576, 14, 14]          --\n",
      "├─PytorchActivationQuantizationHolder: 1-102       [1, 576, 14, 14]          --\n",
      "├─PytorchQuantizationWrapper: 1-103                [1, 96, 14, 14]           55,296\n",
      "│    └─Conv2d: 2-36                                [1, 96, 14, 14]           96\n",
      "├─PytorchActivationQuantizationHolder: 1-104       [1, 96, 14, 14]           --\n",
      "├─PytorchActivationQuantizationHolder: 1-105       [1, 96, 14, 14]           --\n",
      "├─PytorchQuantizationWrapper: 1-106                [1, 576, 14, 14]          55,296\n",
      "│    └─Conv2d: 2-37                                [1, 576, 14, 14]          576\n",
      "├─ReLU6: 1-107                                     [1, 576, 14, 14]          --\n",
      "├─PytorchActivationQuantizationHolder: 1-108       [1, 576, 14, 14]          --\n",
      "├─PytorchQuantizationWrapper: 1-109                [1, 576, 14, 14]          5,184\n",
      "│    └─Conv2d: 2-38                                [1, 576, 14, 14]          576\n",
      "├─ReLU6: 1-110                                     [1, 576, 14, 14]          --\n",
      "├─PytorchActivationQuantizationHolder: 1-111       [1, 576, 14, 14]          --\n",
      "├─PytorchQuantizationWrapper: 1-112                [1, 96, 14, 14]           55,296\n",
      "│    └─Conv2d: 2-39                                [1, 96, 14, 14]           96\n",
      "├─PytorchActivationQuantizationHolder: 1-113       [1, 96, 14, 14]           --\n",
      "├─PytorchActivationQuantizationHolder: 1-114       [1, 96, 14, 14]           --\n",
      "├─PytorchQuantizationWrapper: 1-115                [1, 576, 14, 14]          55,296\n",
      "│    └─Conv2d: 2-40                                [1, 576, 14, 14]          576\n",
      "├─ReLU6: 1-116                                     [1, 576, 14, 14]          --\n",
      "├─PytorchActivationQuantizationHolder: 1-117       [1, 576, 14, 14]          --\n",
      "├─PytorchQuantizationWrapper: 1-118                [1, 576, 7, 7]            5,184\n",
      "│    └─Conv2d: 2-41                                [1, 576, 7, 7]            576\n",
      "├─ReLU6: 1-119                                     [1, 576, 7, 7]            --\n",
      "├─PytorchActivationQuantizationHolder: 1-120       [1, 576, 7, 7]            --\n",
      "├─PytorchQuantizationWrapper: 1-121                [1, 160, 7, 7]            92,160\n",
      "│    └─Conv2d: 2-42                                [1, 160, 7, 7]            160\n",
      "├─PytorchActivationQuantizationHolder: 1-122       [1, 160, 7, 7]            --\n",
      "├─PytorchQuantizationWrapper: 1-123                [1, 960, 7, 7]            153,600\n",
      "│    └─Conv2d: 2-43                                [1, 960, 7, 7]            960\n",
      "├─ReLU6: 1-124                                     [1, 960, 7, 7]            --\n",
      "├─PytorchActivationQuantizationHolder: 1-125       [1, 960, 7, 7]            --\n",
      "├─PytorchQuantizationWrapper: 1-126                [1, 960, 7, 7]            8,640\n",
      "│    └─Conv2d: 2-44                                [1, 960, 7, 7]            960\n",
      "├─ReLU6: 1-127                                     [1, 960, 7, 7]            --\n",
      "├─PytorchActivationQuantizationHolder: 1-128       [1, 960, 7, 7]            --\n",
      "├─PytorchQuantizationWrapper: 1-129                [1, 160, 7, 7]            153,600\n",
      "│    └─Conv2d: 2-45                                [1, 160, 7, 7]            160\n",
      "├─PytorchActivationQuantizationHolder: 1-130       [1, 160, 7, 7]            --\n",
      "├─PytorchActivationQuantizationHolder: 1-131       [1, 160, 7, 7]            --\n",
      "├─PytorchQuantizationWrapper: 1-132                [1, 960, 7, 7]            153,600\n",
      "│    └─Conv2d: 2-46                                [1, 960, 7, 7]            960\n",
      "├─ReLU6: 1-133                                     [1, 960, 7, 7]            --\n",
      "├─PytorchActivationQuantizationHolder: 1-134       [1, 960, 7, 7]            --\n",
      "├─PytorchQuantizationWrapper: 1-135                [1, 960, 7, 7]            8,640\n",
      "│    └─Conv2d: 2-47                                [1, 960, 7, 7]            960\n",
      "├─ReLU6: 1-136                                     [1, 960, 7, 7]            --\n",
      "├─PytorchActivationQuantizationHolder: 1-137       [1, 960, 7, 7]            --\n",
      "├─PytorchQuantizationWrapper: 1-138                [1, 160, 7, 7]            153,600\n",
      "│    └─Conv2d: 2-48                                [1, 160, 7, 7]            160\n",
      "├─PytorchActivationQuantizationHolder: 1-139       [1, 160, 7, 7]            --\n",
      "├─PytorchActivationQuantizationHolder: 1-140       [1, 160, 7, 7]            --\n",
      "├─PytorchQuantizationWrapper: 1-141                [1, 960, 7, 7]            153,600\n",
      "│    └─Conv2d: 2-49                                [1, 960, 7, 7]            960\n",
      "├─ReLU6: 1-142                                     [1, 960, 7, 7]            --\n",
      "├─PytorchActivationQuantizationHolder: 1-143       [1, 960, 7, 7]            --\n",
      "├─PytorchQuantizationWrapper: 1-144                [1, 960, 7, 7]            8,640\n",
      "│    └─Conv2d: 2-50                                [1, 960, 7, 7]            960\n",
      "├─ReLU6: 1-145                                     [1, 960, 7, 7]            --\n",
      "├─PytorchActivationQuantizationHolder: 1-146       [1, 960, 7, 7]            --\n",
      "├─PytorchQuantizationWrapper: 1-147                [1, 320, 7, 7]            307,200\n",
      "│    └─Conv2d: 2-51                                [1, 320, 7, 7]            320\n",
      "├─PytorchActivationQuantizationHolder: 1-148       [1, 320, 7, 7]            --\n",
      "├─PytorchQuantizationWrapper: 1-149                [1, 1280, 7, 7]           409,600\n",
      "│    └─Conv2d: 2-52                                [1, 1280, 7, 7]           1,280\n",
      "├─ReLU6: 1-150                                     [1, 1280, 7, 7]           --\n",
      "├─PytorchActivationQuantizationHolder: 1-151       [1, 1280, 7, 7]           --\n",
      "├─PytorchActivationQuantizationHolder: 1-152       [1, 1280, 1, 1]           --\n",
      "├─Dropout: 1-153                                   [1, 1280]                 --\n",
      "├─PytorchQuantizationWrapper: 1-154                [1, 1000]                 1,280,000\n",
      "│    └─Linear: 2-53                                [1, 1000]                 1,000\n",
      "├─PytorchActivationQuantizationHolder: 1-155       [1, 1000]                 --\n",
      "====================================================================================================\n",
      "Total params: 3,487,816\n",
      "Trainable params: 18,056\n",
      "Non-trainable params: 3,469,760\n",
      "Total mult-adds (M): 6.68\n",
      "====================================================================================================\n",
      "Input size (MB): 0.60\n",
      "Forward/backward pass size (MB): 53.43\n",
      "Params size (MB): 0.07\n",
      "Estimated Total Size (MB): 54.11\n",
      "====================================================================================================\n",
      "layer features_0_0_bn.weight\n",
      "layer features_0_0_bn.layer.bias\n",
      "layer features_1_conv_0_0_bn.weight\n",
      "layer features_1_conv_0_0_bn.layer.bias\n",
      "layer features_1_conv_1_bn.weight\n",
      "layer features_1_conv_1_bn.layer.bias\n",
      "layer features_2_conv_0_0_bn.weight\n",
      "layer features_2_conv_0_0_bn.layer.bias\n",
      "layer features_2_conv_1_0_bn.weight\n",
      "layer features_2_conv_1_0_bn.layer.bias\n",
      "layer features_2_conv_2_bn.weight\n",
      "layer features_2_conv_2_bn.layer.bias\n",
      "layer features_3_conv_0_0_bn.weight\n",
      "layer features_3_conv_0_0_bn.layer.bias\n",
      "layer features_3_conv_1_0_bn.weight\n",
      "layer features_3_conv_1_0_bn.layer.bias\n",
      "layer features_3_conv_2_bn.weight\n",
      "layer features_3_conv_2_bn.layer.bias\n",
      "layer features_4_conv_0_0_bn.weight\n",
      "layer features_4_conv_0_0_bn.layer.bias\n",
      "layer features_4_conv_1_0_bn.weight\n",
      "layer features_4_conv_1_0_bn.layer.bias\n",
      "layer features_4_conv_2_bn.weight\n",
      "layer features_4_conv_2_bn.layer.bias\n",
      "layer features_5_conv_0_0_bn.weight\n",
      "layer features_5_conv_0_0_bn.layer.bias\n",
      "layer features_5_conv_1_0_bn.weight\n",
      "layer features_5_conv_1_0_bn.layer.bias\n",
      "layer features_5_conv_2_bn.weight\n",
      "layer features_5_conv_2_bn.layer.bias\n",
      "layer features_6_conv_0_0_bn.weight\n",
      "layer features_6_conv_0_0_bn.layer.bias\n",
      "layer features_6_conv_1_0_bn.weight\n",
      "layer features_6_conv_1_0_bn.layer.bias\n",
      "layer features_6_conv_2_bn.weight\n",
      "layer features_6_conv_2_bn.layer.bias\n",
      "layer features_7_conv_0_0_bn.weight\n",
      "layer features_7_conv_0_0_bn.layer.bias\n",
      "layer features_7_conv_1_0_bn.weight\n",
      "layer features_7_conv_1_0_bn.layer.bias\n",
      "layer features_7_conv_2_bn.weight\n",
      "layer features_7_conv_2_bn.layer.bias\n",
      "layer features_8_conv_0_0_bn.weight\n",
      "layer features_8_conv_0_0_bn.layer.bias\n",
      "layer features_8_conv_1_0_bn.weight\n",
      "layer features_8_conv_1_0_bn.layer.bias\n",
      "layer features_8_conv_2_bn.weight\n",
      "layer features_8_conv_2_bn.layer.bias\n",
      "layer features_9_conv_0_0_bn.weight\n",
      "layer features_9_conv_0_0_bn.layer.bias\n",
      "layer features_9_conv_1_0_bn.weight\n",
      "layer features_9_conv_1_0_bn.layer.bias\n",
      "layer features_9_conv_2_bn.weight\n",
      "layer features_9_conv_2_bn.layer.bias\n",
      "layer features_10_conv_0_0_bn.weight\n",
      "layer features_10_conv_0_0_bn.layer.bias\n",
      "layer features_10_conv_1_0_bn.weight\n",
      "layer features_10_conv_1_0_bn.layer.bias\n",
      "layer features_10_conv_2_bn.weight\n",
      "layer features_10_conv_2_bn.layer.bias\n",
      "layer features_11_conv_0_0_bn.weight\n",
      "layer features_11_conv_0_0_bn.layer.bias\n",
      "layer features_11_conv_1_0_bn.weight\n",
      "layer features_11_conv_1_0_bn.layer.bias\n",
      "layer features_11_conv_2_bn.weight\n",
      "layer features_11_conv_2_bn.layer.bias\n",
      "layer features_12_conv_0_0_bn.weight\n",
      "layer features_12_conv_0_0_bn.layer.bias\n",
      "layer features_12_conv_1_0_bn.weight\n",
      "layer features_12_conv_1_0_bn.layer.bias\n",
      "layer features_12_conv_2_bn.weight\n",
      "layer features_12_conv_2_bn.layer.bias\n",
      "layer features_13_conv_0_0_bn.weight\n",
      "layer features_13_conv_0_0_bn.layer.bias\n",
      "layer features_13_conv_1_0_bn.weight\n",
      "layer features_13_conv_1_0_bn.layer.bias\n",
      "layer features_13_conv_2_bn.weight\n",
      "layer features_13_conv_2_bn.layer.bias\n",
      "layer features_14_conv_0_0_bn.weight\n",
      "layer features_14_conv_0_0_bn.layer.bias\n",
      "layer features_14_conv_1_0_bn.weight\n",
      "layer features_14_conv_1_0_bn.layer.bias\n",
      "layer features_14_conv_2_bn.weight\n",
      "layer features_14_conv_2_bn.layer.bias\n",
      "layer features_15_conv_0_0_bn.weight\n",
      "layer features_15_conv_0_0_bn.layer.bias\n",
      "layer features_15_conv_1_0_bn.weight\n",
      "layer features_15_conv_1_0_bn.layer.bias\n",
      "layer features_15_conv_2_bn.weight\n",
      "layer features_15_conv_2_bn.layer.bias\n",
      "layer features_16_conv_0_0_bn.weight\n",
      "layer features_16_conv_0_0_bn.layer.bias\n",
      "layer features_16_conv_1_0_bn.weight\n",
      "layer features_16_conv_1_0_bn.layer.bias\n",
      "layer features_16_conv_2_bn.weight\n",
      "layer features_16_conv_2_bn.layer.bias\n",
      "layer features_17_conv_0_0_bn.weight\n",
      "layer features_17_conv_0_0_bn.layer.bias\n",
      "layer features_17_conv_1_0_bn.weight\n",
      "layer features_17_conv_1_0_bn.layer.bias\n",
      "layer features_17_conv_2_bn.weight\n",
      "layer features_17_conv_2_bn.layer.bias\n",
      "layer features_18_0_bn.weight\n",
      "layer features_18_0_bn.layer.bias\n",
      "layer classifier_1.weight\n",
      "layer classifier_1.layer.bias\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo\n",
    "from torchinfo import summary\n",
    "quantized_model = data[\"quantized_model\"]\n",
    "quantizer_object = quantized_model.features_0_2_activation_holder_quantizer\n",
    "\n",
    "quantized_model = data[\"quantized_model\"]\n",
    "\n",
    "print(quantized_model.state_dict().keys())\n",
    "\n",
    "relu_layer_indices = []\n",
    "\n",
    "print(summary(\n",
    "    quantized_model,\n",
    "    input_size=(1, 3, 224, 224),\n",
    "    col_names=[\"output_size\", \"num_params\"],\n",
    "))\n",
    "\n",
    "for i, layer in enumerate(quantized_model.state_dict().keys()):\n",
    "    print('layer', i, layer)\n",
    "    # Convert the layer's configuration to a string\n",
    "    #layer_config_str = str(layer.get_config())\n",
    "\n",
    "    #layer_class_str = str(layer.__class__.__name__)\n",
    "\n",
    "    # Check if \"relu\" is mentioned in the layer's configuration or class name\n",
    "    #if 'relu' in layer_config_str.lower() or 'relu' in layer_class_str.lower():\n",
    "    #    relu_layer_indices.append(i)\n",
    "\n",
    "#print(\"Layer indices potentially using ReLU:\", relu_layer_indices)\n",
    "#print(\"Number of relu layers \" + str(len(relu_layer_indices)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f34133-8ed4-429a-a225-6fb6a6f5b207",
   "metadata": {
    "id": "43f34133-8ed4-429a-a225-6fb6a6f5b207"
   },
   "outputs": [],
   "source": [
    "for error_method, data in quantized_models_dict.items():\n",
    "    quantized_model = data[\"quantized_model\"]\n",
    "    print(quantized_model.layers[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c1645e-205c-4d9a-8af3-e497b3addec1",
   "metadata": {
    "id": "01c1645e-205c-4d9a-8af3-e497b3addec1"
   },
   "source": [
    "Copyright 2024 Sony Semiconductor Israel, Inc. All rights reserved.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ve310_1_pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
